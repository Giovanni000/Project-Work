{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 3: Funzione di Inferenza Unica\n",
        "\n",
        "Funzione che combina classificatore OCCLUSION e autoencoder per classificare\n",
        "un'immagine come \"OK\", \"KO\" o \"OCCLUSION\".\n",
        "\n",
        "**Pipeline:**\n",
        "1. STEP 1 - Occlusione: Verifica se l'immagine è occlusa → se sì, ritorna \"OCCLUSION\"\n",
        "2. STEP 2 - Anomaly Detection: Se visibile, verifica se è anomalo → se errore > threshold → \"KO\", altrimenti \"OK\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Clona repository GitHub e monta Google Drive per i dati\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Opzione 1: Clona da GitHub (consigliato per sviluppo)\n",
        "# Sostituisci con il tuo repository URL\n",
        "GITHUB_REPO = \"https://github.com/Giovanni000/Project-Work.git\"  # ⚠️ MODIFICA QUESTO!\n",
        "REPO_DIR = \"/content/project\"\n",
        "\n",
        "# Clona repository (se non esiste già)\n",
        "if not Path(REPO_DIR).exists():\n",
        "    !git clone {GITHUB_REPO} {REPO_DIR}\n",
        "\n",
        "# Cambia directory al repository\n",
        "os.chdir(REPO_DIR)\n",
        "print(f\"Repository directory: {os.getcwd()}\")\n",
        "\n",
        "# Opzione 2: Monta Google Drive solo per i dati (immagini)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path ai dati su Drive\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/Project Work/Data\")\n",
        "print(f\"Data directory: {DATA_ROOT}\")\n",
        "\n",
        "# Path locale (se hai copiato le immagini in locale durante step1/step2)\n",
        "LOCAL_DATA_DIR = Path(\"/content/local_data\")\n",
        "print(f\"Local data directory: {LOCAL_DATA_DIR}\")\n",
        "\n",
        "# Determina quale path usare (locale se esiste, altrimenti Drive)\n",
        "if LOCAL_DATA_DIR.exists() and (LOCAL_DATA_DIR / \"connectors\").exists():\n",
        "    IMAGE_BASE_PATH = LOCAL_DATA_DIR\n",
        "    print(\"✅ Usando immagini in locale (più veloce)\")\n",
        "else:\n",
        "    IMAGE_BASE_PATH = DATA_ROOT\n",
        "    print(\"ℹ️  Usando immagini su Drive\")\n",
        "\n",
        "# Import necessari\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "# Importa classi e funzioni dai notebook precedenti\n",
        "# Nota: Assicurati di aver eseguito step1 e step2 prima di questo notebook\n",
        "\n",
        "# Verifica device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importa Modelli e Classi\n",
        "\n",
        "**Nota:** Esegui prima i notebook `step1_occlusion_classifier.ipynb` e `step2_autoencoder.ipynb` per avere i modelli addestrati.\n",
        "\n",
        "Oppure importa le classi se hai i file Python:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importa le classi necessarie\n",
        "# Se stai usando i file Python:\n",
        "# from step1_occlusion_classifier import OcclusionCNN\n",
        "# from step2_autoencoder import ConvAE\n",
        "\n",
        "# Se stai usando solo i notebook, le classi dovrebbero essere già in memoria\n",
        "# dopo aver eseguito step1 e step2. Altrimenti, definiscile qui (vedi celle successive)\n",
        "\n",
        "# Funzioni helper per caricare i modelli\n",
        "def load_occlusion_model(device=None):\n",
        "    \"\"\"Carica il modello classificatore OCCLUSION.\"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # Se OcclusionCNN non è definita, devi importarla o definirla\n",
        "    # Per ora assumiamo che sia già stata eseguita step1\n",
        "    try:\n",
        "        model = OcclusionCNN().to(device)\n",
        "    except NameError:\n",
        "        raise NameError(\"OcclusionCNN non definita. Esegui prima step1_occlusion_classifier.ipynb\")\n",
        "    \n",
        "    model_path = Path(\"models/occlusion_cnn.pth\")\n",
        "    if not model_path.exists():\n",
        "        raise FileNotFoundError(f\"Modello non trovato: {model_path}\")\n",
        "    \n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_ae_and_threshold(device=None):\n",
        "    \"\"\"Carica l'autoencoder e il threshold.\"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # Se ConvAE non è definita, devi importarla o definirla\n",
        "    try:\n",
        "        model = ConvAE().to(device)\n",
        "    except NameError:\n",
        "        raise NameError(\"ConvAE non definita. Esegui prima step2_autoencoder.ipynb\")\n",
        "    \n",
        "    model_path = Path(\"models/ae_conv.pth\")\n",
        "    if not model_path.exists():\n",
        "        raise FileNotFoundError(f\"Modello non trovato: {model_path}\")\n",
        "    \n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    \n",
        "    threshold_path = Path(\"models/ae_threshold.npy\")\n",
        "    if not threshold_path.exists():\n",
        "        raise FileNotFoundError(f\"Threshold non trovato: {threshold_path}\")\n",
        "    \n",
        "    threshold = np.load(threshold_path)\n",
        "    return model, threshold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funzioni di Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_image(image_path, device=None):\n",
        "    \"\"\"\n",
        "    Preprocessa un'immagine per l'inferenza (classificatore OCCLUSION).\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # Trasformazioni (stesse del training)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    # Carica e preprocessa\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_tensor = transform(image)\n",
        "    image_tensor = image_tensor.unsqueeze(0)  # Aggiungi dimensione batch\n",
        "    image_tensor = image_tensor.to(device)\n",
        "    \n",
        "    return image_tensor\n",
        "\n",
        "\n",
        "def preprocess_image_for_ae(image_path, device=None):\n",
        "    \"\"\"\n",
        "    Preprocessa un'immagine per l'autoencoder (senza normalizzazione ImageNet).\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # Trasformazioni (stesse del training AE)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),  # Già in [0, 1]\n",
        "    ])\n",
        "    \n",
        "    # Carica e preprocessa\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_tensor = transform(image)\n",
        "    image_tensor = image_tensor.unsqueeze(0)  # Aggiungi dimensione batch\n",
        "    image_tensor = image_tensor.to(device)\n",
        "    \n",
        "    return image_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funzione di Classificazione Principale\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_connector(image_path, device=None):\n",
        "    \"\"\"\n",
        "    Classifica un connettore come \"OK\", \"KO\" o \"OCCLUSION\".\n",
        "    \n",
        "    Pipeline:\n",
        "    1. STEP 1 - Occlusione: Verifica se l'immagine è occlusa\n",
        "       - Se occlusa → ritorna \"OCCLUSION\"\n",
        "    2. STEP 2 - Anomaly Detection: Se visibile, verifica se è anomalo\n",
        "       - Se errore ricostruzione > threshold → ritorna \"KO\"\n",
        "       - Altrimenti → ritorna \"OK\"\n",
        "    \n",
        "    Args:\n",
        "        image_path: Path all'immagine del connettore\n",
        "        device: Device (cuda/cpu)\n",
        "    \n",
        "    Returns:\n",
        "        str: \"OK\", \"KO\" o \"OCCLUSION\"\n",
        "        \n",
        "    Note:\n",
        "        - \"OCCLUSION\" = immagine non leggibile (cavi o altro coprono la zona critica)\n",
        "        - \"OK\" = connettore visibile e simile ai campioni OK di training\n",
        "        - \"KO\" = connettore visibile ma anomalo rispetto ai campioni OK\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # Carica modelli (caricati una volta e riutilizzati)\n",
        "    try:\n",
        "        occ_model = load_occlusion_model(device)\n",
        "        ae_model, threshold = load_ae_and_threshold(device)\n",
        "    except (FileNotFoundError, NameError) as e:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Modelli non trovati o classi non definite. \"\n",
        "            f\"Assicurati di aver eseguito step1 e step2. Errore: {e}\"\n",
        "        )\n",
        "    \n",
        "    # STEP 1: Verifica occlusione\n",
        "    x_occ = preprocess_image(image_path, device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        logits = occ_model(x_occ)\n",
        "        pred_vis = torch.argmax(logits, dim=1).item()\n",
        "    \n",
        "    # Se pred_vis == 0 → OCCLUSION\n",
        "    if pred_vis == 0:\n",
        "        return \"OCCLUSION\"\n",
        "    \n",
        "    # STEP 2: Anomaly detection (solo se visibile)\n",
        "    x_ae = preprocess_image_for_ae(image_path, device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        reconstructed = ae_model(x_ae)\n",
        "        # Calcola errore MSE medio su [C, H, W]\n",
        "        mse = nn.MSELoss(reduction='mean')\n",
        "        error = mse(reconstructed, x_ae).item()\n",
        "    \n",
        "    # Se errore > threshold → KO (anomalo)\n",
        "    if error > threshold:\n",
        "        return \"KO\"\n",
        "    else:\n",
        "        return \"OK\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# I modelli vengono caricati automaticamente da classify_connector()\n",
        "# Ma se vuoi caricarli manualmente per testare:\n",
        "\n",
        "# Nota: Le classi OcclusionCNN e ConvAE devono essere in memoria\n",
        "# (eseguite da step1 e step2) oppure importate dai file Python\n",
        "\n",
        "# Esempio di caricamento manuale:\n",
        "# occ_model = load_occlusion_model(device)\n",
        "# ae_model, threshold = load_ae_and_threshold(device)\n",
        "# print(\"Modelli caricati con successo!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Inferenza\n",
        "\n",
        "Testa la funzione di classificazione su alcune immagini.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test su alcune immagini di esempio\n",
        "# Usa IMAGE_BASE_PATH (locale o Drive) per costruire i path corretti\n",
        "test_filenames = [\n",
        "    (\"conn1\", \"20251106110559_TOP.png\"),\n",
        "    (\"conn2\", \"20251106110559_TOP.png\"),\n",
        "    (\"conn3\", \"20251106110559_TOP.png\"),\n",
        "]\n",
        "\n",
        "# Costruisci i path completi\n",
        "test_images = [\n",
        "    str(IMAGE_BASE_PATH / \"connectors\" / connector / filename)\n",
        "    for connector, filename in test_filenames\n",
        "]\n",
        "\n",
        "print(\"Test classificazione:\\n\")\n",
        "print(f\"Base path: {IMAGE_BASE_PATH}\\n\")\n",
        "\n",
        "for img_path in test_images:\n",
        "    img_path_obj = Path(img_path)\n",
        "    if img_path_obj.exists():\n",
        "        try:\n",
        "            result = classify_connector(str(img_path_obj), device=device)\n",
        "            print(f\"  {img_path_obj.name} ({img_path_obj.parent.name}): {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  {img_path_obj.name}: ❌ ERRORE - {e}\")\n",
        "    else:\n",
        "        print(f\"  {img_path}: ⚠️  Immagine non trovata\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
