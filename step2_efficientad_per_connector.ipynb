{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 2: EfficientAD-M per Anomaly Detection - UN MODELLO PER OGNI CONNETTORE\n",
        "\n",
        "Questo notebook addestra **9 modelli EfficientAD-M separati**, uno per ogni connettore (conn1, conn2, ..., conn9).\n",
        "\n",
        "Ogni modello avr√† il suo threshold specifico calcolato solo sui dati OK del rispettivo connettore.\n",
        "\n",
        "**EfficientAD-M** √® un metodo di anomaly detection basato su Teacher-Student architecture:\n",
        "- **Teacher**: ResNet18 pre-addestrato su ImageNet (congelato)\n",
        "- **Student**: ResNet18 non pre-addestrato (addestrato su OK)\n",
        "- **Anomaly score**: differenza tra feature teacher e student\n",
        "\n",
        "Funziona meglio degli autoencoder quando le anomalie sono strutturali/geometriche (come nel nostro caso).\n",
        "\n",
        "**NOTA**: Le immagini sono gi√† in grayscale e normalizzate nel preprocessing. Le carichiamo come RGB per compatibilit√† con ResNet pre-addestrato.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Clona repository GitHub e monta Google Drive per i dati\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Opzione 1: Clona da GitHub (consigliato per sviluppo)\n",
        "# Sostituisci con il tuo repository URL\n",
        "GITHUB_REPO = \"https://github.com/Giovanni000/Project-Work.git\"  # ‚ö†Ô∏è MODIFICA QUESTO!\n",
        "REPO_DIR = \"/content/project\"\n",
        "\n",
        "# Clona repository (se non esiste gi√†)\n",
        "if not Path(REPO_DIR).exists():\n",
        "    !git clone {GITHUB_REPO} {REPO_DIR}\n",
        "else:\n",
        "    os.chdir(REPO_DIR)\n",
        "    !git pull\n",
        "\n",
        "# Cambia directory al repository\n",
        "os.chdir(REPO_DIR)\n",
        "# Se il clone crea una sottocartella, entra dentro\n",
        "subdirs = [d for d in Path(REPO_DIR).iterdir() if d.is_dir() and not d.name.startswith('.')]\n",
        "if len(subdirs) == 1:\n",
        "    os.chdir(subdirs[0])\n",
        "\n",
        "print(f\"Repository directory: {os.getcwd()}\")\n",
        "\n",
        "# Opzione 2: Monta Google Drive solo per i dati (immagini)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path ai dati su Drive\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/Project Work/Data\")\n",
        "print(f\"Data directory: {DATA_ROOT}\")\n",
        "\n",
        "# ‚ö†Ô∏è IMPORTANTE: Le immagini su Drive sono LENTE da caricare durante il training!\n",
        "# Se il training √® troppo lento, considera di copiare le immagini in locale prima\n",
        "\n",
        "# Import necessari\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seed per riproducibilit√†\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Verifica device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU: {gpu_name}\")\n",
        "    print(f\"VRAM: {gpu_memory:.1f} GB\")\n",
        "    if \"T4\" in gpu_name:\n",
        "        print(\"‚úÖ Tesla T4 rilevata - Parametri ottimizzati per questa GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verifica/Crea Dataset CSV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se data/dataset.csv non esiste, crealo automaticamente\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "dataset_csv = Path(\"data/dataset.csv\")\n",
        "\n",
        "if not dataset_csv.exists():\n",
        "    print(\"‚ö†Ô∏è  data/dataset.csv non trovato. Creazione automatica...\")\n",
        "    \n",
        "    # Carica features_labeled.csv\n",
        "    features_csv = Path(\"features_labeled.csv\")\n",
        "    if not features_csv.exists():\n",
        "        # Prova path alternativo\n",
        "        features_csv = Path(\"/content/project/features_labeled.csv\")\n",
        "    \n",
        "    if not features_csv.exists():\n",
        "        raise FileNotFoundError(f\"features_labeled.csv non trovato in {features_csv}\")\n",
        "    \n",
        "    print(f\"Leggendo CSV: {features_csv}...\")\n",
        "    df = pd.read_csv(features_csv)\n",
        "    print(f\"CSV caricato: {len(df)} righe\")\n",
        "    \n",
        "    # Aggrega PARTIAL OCCLUSION con OCCLUSION\n",
        "    df['label_merged'] = df['label'].replace('PARTIAL OCCLUSION', 'OCCLUSION')\n",
        "    \n",
        "    # Costruisci path immagini (su Drive)\n",
        "    DRIVE_DATA_BASE = \"/content/drive/MyDrive/Project Work/Data\"\n",
        "    df['image_path'] = df.apply(\n",
        "        lambda row: f\"{DRIVE_DATA_BASE}/connectors/{row['connector_name']}/{row['filename']}\",\n",
        "        axis=1\n",
        "    )\n",
        "    \n",
        "    # Verifica esistenza immagini\n",
        "    print(\"Verificando esistenza immagini...\")\n",
        "    existing = []\n",
        "    for idx, path in enumerate(df['image_path']):\n",
        "        if Path(path).exists():\n",
        "            existing.append(idx)\n",
        "    \n",
        "    print(f\"Immagini trovate: {len(existing)}/{len(df)}\")\n",
        "    \n",
        "    if len(existing) == 0:\n",
        "        print(\"‚ö†Ô∏è  PROBLEMA: Nessuna immagine trovata!\")\n",
        "        print(\"Verifica che Drive sia montato e che i path siano corretti.\")\n",
        "    \n",
        "    # Filtra solo immagini esistenti\n",
        "    df_valid = df.iloc[existing].copy()\n",
        "    \n",
        "    # Prepara CSV finale\n",
        "    output_df = df_valid[['image_path', 'label_merged', 'connector_name']].copy()\n",
        "    output_df.rename(columns={'label_merged': 'label'}, inplace=True)\n",
        "    \n",
        "    # Crea cartella data se non esiste\n",
        "    dataset_csv.parent.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Salva\n",
        "    output_df.to_csv(dataset_csv, index=False)\n",
        "    print(f\"‚úÖ Dataset preparato: {len(output_df)} righe\")\n",
        "    print(f\"Distribuzione label:\")\n",
        "    print(output_df['label'].value_counts())\n",
        "else:\n",
        "    print(f\"‚úÖ Dataset trovato: {dataset_csv}\")\n",
        "    df_check = pd.read_csv(dataset_csv)\n",
        "    print(f\"  Righe: {len(df_check)}\")\n",
        "    print(f\"  Colonne: {list(df_check.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configurazione EfficientAD-M\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURAZIONE EFFICIENTAD-M\n",
        "# ============================================================================\n",
        "\n",
        "# Dimensioni immagine (coerente con il progetto: 128x128)\n",
        "IMG_SIZE = 128\n",
        "\n",
        "# Parametri training\n",
        "BATCH_SIZE = 32  # Ottimizzato per Tesla T4\n",
        "NUM_EPOCHS = 25  # EfficientAD-M converge velocemente\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# Threshold\n",
        "THRESHOLD_MULTIPLIER = 2.5  # Threshold = mu + THRESHOLD_MULTIPLIER * sigma\n",
        "\n",
        "# DataLoader\n",
        "NUM_WORKERS = 2  # Ottimizzato per Tesla T4\n",
        "\n",
        "# Device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Multi-layer feature configuration\n",
        "FEATURE_LAYERS = [\"layer2\", \"layer3\", \"layer4\"]  # Layers to use for anomaly detection\n",
        "FEATURE_LAYER_WEIGHTS = {\n",
        "    \"layer2\": 1.0,\n",
        "    \"layer3\": 1.0,\n",
        "    \"layer4\": 1.0,\n",
        "}\n",
        "\n",
        "# Spatial mask configuration\n",
        "SPATIAL_MASK_MIN_WEIGHT = 0.5  # Minimum weight in spatial mask\n",
        "SPATIAL_MASK_MAX_WEIGHT = 2.0  # Maximum weight in spatial mask\n",
        "\n",
        "# Robust score configuration\n",
        "TOP_K_PERCENT = 0.01  # Top 1% of anomaly values for robust score\n",
        "\n",
        "# Debug/Visualization configuration\n",
        "DEBUG_CONNECTOR = \"conn1\"  # Connector to use for visualization/debugging\n",
        "\n",
        "print(f\"Configurazione EfficientAD-M:\")\n",
        "print(f\"  IMG_SIZE: {IMG_SIZE}\")\n",
        "print(f\"  BATCH_SIZE: {BATCH_SIZE}\")\n",
        "print(f\"  NUM_EPOCHS: {NUM_EPOCHS}\")\n",
        "print(f\"  LEARNING_RATE: {LEARNING_RATE}\")\n",
        "print(f\"  THRESHOLD_MULTIPLIER: {THRESHOLD_MULTIPLIER}\")\n",
        "print(f\"  FEATURE_LAYERS: {FEATURE_LAYERS}\")\n",
        "print(f\"  TOP_K_PERCENT: {TOP_K_PERCENT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Class (solo OK, filtrato per connettore)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EfficientADDatasetPerConnector(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset PyTorch per EfficientAD-M di un singolo connettore.\n",
        "    Contiene solo immagini OK del connettore specificato.\n",
        "    \n",
        "    NOTA: Le immagini sono gi√† in grayscale e normalizzate nel preprocessing.\n",
        "    Le carichiamo come RGB per compatibilit√† con ResNet pre-addestrato.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, csv_path, connector_name, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_path: Path al CSV con colonne 'image_path', 'label', 'connector_name'\n",
        "            connector_name: Nome del connettore (es. 'conn1', 'conn2', ...)\n",
        "            transform: Trasformazioni da applicare alle immagini\n",
        "        \"\"\"\n",
        "        df = pd.read_csv(csv_path)\n",
        "        # Filtra solo OK del connettore specificato\n",
        "        self.df = df[(df['label'] == 'OK') & (df['connector_name'] == connector_name)].copy().reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        \n",
        "        print(f\"Dataset EfficientAD per {connector_name}: {len(self.df)} immagini OK\")\n",
        "        if len(self.df) == 0:\n",
        "            raise ValueError(f\"Nessuna immagine OK trovata per {connector_name}!\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image_path = row['image_path']\n",
        "        \n",
        "        # Carica immagine (ottimizzato: evita lazy loading)\n",
        "        try:\n",
        "            # Le immagini sono gi√† grayscale nel preprocessing, ma le carichiamo come RGB\n",
        "            # per compatibilit√† con ResNet pre-addestrato\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            image.load()  # Forza caricamento completo\n",
        "        except Exception as e:\n",
        "            print(f\"Errore caricamento {image_path}: {e}\")\n",
        "            # Fallback: immagine nera\n",
        "            image = Image.new('RGB', (IMG_SIZE, IMG_SIZE), (0, 0, 0))\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_spatial_weight_mask_for_connector(connector_name, csv_path=\"data/dataset.csv\",\n",
        "                                              img_size=IMG_SIZE, save_dir=\"models\",\n",
        "                                              min_weight=SPATIAL_MASK_MIN_WEIGHT, \n",
        "                                              max_weight=SPATIAL_MASK_MAX_WEIGHT):\n",
        "    \"\"\"\n",
        "    For the given connector, compute a spatial weight mask W[h, w] from all OK images:\n",
        "    - load all OK images for that connector\n",
        "    - resize to (img_size, img_size)\n",
        "    - convert to grayscale or keep RGB but reduce to a single channel statistic\n",
        "    - compute per-pixel mean and std over the OK stack\n",
        "    - transform std into a weight map:\n",
        "        - lower std -> higher weight (stable regions)\n",
        "        - higher std -> lower weight (variable regions)\n",
        "    - normalize and clamp to [min_weight, max_weight]\n",
        "    - save the final W as a .npy file: spatial_mask_{connector_name}.npy in `save_dir`\n",
        "    - return W as a numpy array [H, W]\n",
        "    \"\"\"\n",
        "    import torch.nn.functional as F\n",
        "    \n",
        "    # Check if mask already exists\n",
        "    models_dir = Path(save_dir)\n",
        "    models_dir.mkdir(exist_ok=True)\n",
        "    mask_path = models_dir / f\"spatial_mask_{connector_name}.npy\"\n",
        "    \n",
        "    if mask_path.exists():\n",
        "        print(f\"  ‚úÖ Spatial mask gi√† esistente per {connector_name}, skip computation\")\n",
        "        return np.load(mask_path)\n",
        "    \n",
        "    print(f\"  üìä Computing spatial weight mask for {connector_name}...\")\n",
        "    \n",
        "    # Read CSV and filter OK images for this connector\n",
        "    df = pd.read_csv(csv_path)\n",
        "    ok_df = df[(df['label'] == 'OK') & (df['connector_name'] == connector_name)].copy()\n",
        "    \n",
        "    if len(ok_df) == 0:\n",
        "        raise ValueError(f\"Nessuna immagine OK trovata per {connector_name}!\")\n",
        "    \n",
        "    print(f\"    Caricando {len(ok_df)} immagini OK...\")\n",
        "    \n",
        "    # Load and stack all OK images\n",
        "    images_stack = []\n",
        "    for idx, row in tqdm(ok_df.iterrows(), total=len(ok_df), desc=\"  Loading images\"):\n",
        "        image_path = row['image_path']\n",
        "        try:\n",
        "            # Load image and convert to RGB\n",
        "            img = Image.open(image_path).convert('RGB')\n",
        "            # Resize to img_size\n",
        "            img = img.resize((img_size, img_size), Image.Resampling.LANCZOS)\n",
        "            # Convert to numpy array and normalize to [0, 1]\n",
        "            img_array = np.array(img, dtype=np.float32) / 255.0\n",
        "            # Convert to grayscale (average over channels)\n",
        "            img_gray = np.mean(img_array, axis=2)  # [H, W]\n",
        "            images_stack.append(img_gray)\n",
        "        except Exception as e:\n",
        "            print(f\"    ‚ö†Ô∏è  Errore caricamento {image_path}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    if len(images_stack) == 0:\n",
        "        raise ValueError(f\"Nessuna immagine valida caricata per {connector_name}!\")\n",
        "    \n",
        "    # Stack all images: [N, H, W]\n",
        "    X = np.stack(images_stack, axis=0)\n",
        "    print(f\"    Stack shape: {X.shape}\")\n",
        "    \n",
        "    # Compute per-pixel standard deviation\n",
        "    std_map = X.std(axis=0)  # [H, W]\n",
        "    \n",
        "    # Normalize std_map to [0, 1]\n",
        "    std_min, std_max = std_map.min(), std_map.max()\n",
        "    if std_max - std_min < 1e-8:\n",
        "        # All values are the same, use uniform weights\n",
        "        std_norm = np.zeros_like(std_map)\n",
        "    else:\n",
        "        std_norm = (std_map - std_min) / (std_max - std_min + 1e-8)\n",
        "    \n",
        "    # Convert to weights: lower std -> higher weight\n",
        "    # Formula: weights = 1.0 / (1.0 + std_norm)\n",
        "    # This gives weights in [0.5, 1.0], then we rescale to [min_weight, max_weight]\n",
        "    weights = 1.0 / (1.0 + std_norm)\n",
        "    \n",
        "    # Rescale to [min_weight, max_weight]\n",
        "    w_min, w_max = weights.min(), weights.max()\n",
        "    if w_max - w_min < 1e-8:\n",
        "        # Uniform weights\n",
        "        weights = np.ones_like(weights) * ((min_weight + max_weight) / 2.0)\n",
        "    else:\n",
        "        weights = min_weight + (weights - w_min) * (max_weight - min_weight) / (w_max - w_min + 1e-8)\n",
        "    \n",
        "    # Save mask\n",
        "    np.save(mask_path, weights)\n",
        "    print(f\"  ‚úÖ Spatial mask salvato in: {mask_path}\")\n",
        "    print(f\"    Weight range: [{weights.min():.3f}, {weights.max():.3f}]\")\n",
        "    \n",
        "    return weights\n",
        "\n",
        "\n",
        "def load_spatial_weight_mask(connector_name, target_size, save_dir=\"models\", device=DEVICE):\n",
        "    \"\"\"\n",
        "    Load spatial_mask_{connector_name}.npy, resize it to target_size = (Hf, Wf),\n",
        "    and return a tensor of shape [1, 1, Hf, Wf] on the given device.\n",
        "    \n",
        "    Args:\n",
        "        connector_name: Name of the connector\n",
        "        target_size: Target size (Hf, Wf) for the mask\n",
        "        save_dir: Directory where masks are saved\n",
        "        device: Device to place the tensor on\n",
        "    \n",
        "    Returns:\n",
        "        mask: Tensor [1, 1, Hf, Wf] on device\n",
        "    \"\"\"\n",
        "    import torch.nn.functional as F\n",
        "    \n",
        "    models_dir = Path(save_dir)\n",
        "    mask_path = models_dir / f\"spatial_mask_{connector_name}.npy\"\n",
        "    \n",
        "    if not mask_path.exists():\n",
        "        raise FileNotFoundError(f\"Spatial mask not found: {mask_path}\")\n",
        "    \n",
        "    # Load mask [H, W]\n",
        "    mask = np.load(mask_path)\n",
        "    \n",
        "    # Convert to torch tensor [1, 1, H, W]\n",
        "    mask_tensor = torch.from_numpy(mask).float().unsqueeze(0).unsqueeze(0)\n",
        "    \n",
        "    # Resize to target_size using bilinear interpolation\n",
        "    if mask_tensor.shape[2:] != target_size:\n",
        "        mask_tensor = F.interpolate(\n",
        "            mask_tensor, \n",
        "            size=target_size, \n",
        "            mode='bilinear', \n",
        "            align_corners=False\n",
        "        )\n",
        "    \n",
        "    # Move to device\n",
        "    mask_tensor = mask_tensor.to(device)\n",
        "    \n",
        "    return mask_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Class (solo OK, filtrato per connettore)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_fused_anomaly_map(teacher_feats, student_feats,\n",
        "                              spatial_mask_fullres,\n",
        "                              feature_layers=FEATURE_LAYERS,\n",
        "                              feature_layer_weights=FEATURE_LAYER_WEIGHTS,\n",
        "                              device=DEVICE):\n",
        "    \"\"\"\n",
        "    Compute fused 2D anomaly map from multi-layer features with spatial mask.\n",
        "    This is the intermediate step before reducing to a scalar score.\n",
        "    \n",
        "    Args:\n",
        "        teacher_feats: Dict[layer_name -> tensor [B, C, Hf, Wf]]\n",
        "        student_feats: Dict[layer_name -> tensor [B, C, Hf, Wf]]\n",
        "        spatial_mask_fullres: Weight map at image resolution [1, 1, H, W]\n",
        "        feature_layers: List of layer names to use\n",
        "        feature_layer_weights: Dict of weights for each layer\n",
        "        device: Device for computation\n",
        "    \n",
        "    Returns:\n",
        "        fused_map: Tensor [B, 1, Href, Wref] - fused anomaly map before scalar aggregation\n",
        "    \"\"\"\n",
        "    import torch.nn.functional as F\n",
        "    \n",
        "    # Determine reference spatial resolution (use layer2 as it has highest resolution)\n",
        "    ref_layer = feature_layers[0]  # Use first layer as reference\n",
        "    ref_feat = teacher_feats[ref_layer]\n",
        "    _, _, Href, Wref = ref_feat.shape\n",
        "    \n",
        "    fused = None\n",
        "    \n",
        "    # Process each layer\n",
        "    for layer_name in feature_layers:\n",
        "        t = teacher_feats[layer_name]  # [B, C, Hf, Wf]\n",
        "        s = student_feats[layer_name]  # [B, C, Hf, Wf]\n",
        "        \n",
        "        # Compute squared difference\n",
        "        diff = (t - s) ** 2  # [B, C, Hf, Wf]\n",
        "        \n",
        "        # Average over channels\n",
        "        amap = diff.mean(dim=1, keepdim=True)  # [B, 1, Hf, Wf]\n",
        "        \n",
        "        # Get layer spatial dimensions\n",
        "        _, _, Hf, Wf = amap.shape\n",
        "        \n",
        "        # Resize spatial mask to layer resolution\n",
        "        mask_resized = F.interpolate(\n",
        "            spatial_mask_fullres,\n",
        "            size=(Hf, Wf),\n",
        "            mode='bilinear',\n",
        "            align_corners=False\n",
        "        )  # [1, 1, Hf, Wf]\n",
        "        \n",
        "        # Apply spatial mask (broadcasting over batch)\n",
        "        amap = amap * mask_resized  # [B, 1, Hf, Wf]\n",
        "        \n",
        "        # Upsample to reference resolution\n",
        "        if (Hf, Wf) != (Href, Wref):\n",
        "            amap = F.interpolate(\n",
        "                amap,\n",
        "                size=(Href, Wref),\n",
        "                mode='bilinear',\n",
        "                align_corners=False\n",
        "            )  # [B, 1, Href, Wref]\n",
        "        \n",
        "        # Accumulate into fused map with layer weight\n",
        "        layer_weight = feature_layer_weights.get(layer_name, 1.0)\n",
        "        if fused is None:\n",
        "            fused = layer_weight * amap\n",
        "        else:\n",
        "            fused = fused + layer_weight * amap\n",
        "    \n",
        "    return fused  # [B, 1, Href, Wref]\n",
        "\n",
        "\n",
        "def compute_anomaly_score_from_features(teacher_feats, student_feats,\n",
        "                                        spatial_mask_fullres,\n",
        "                                        feature_layers=FEATURE_LAYERS,\n",
        "                                        feature_layer_weights=FEATURE_LAYER_WEIGHTS,\n",
        "                                        topk_percent=TOP_K_PERCENT,\n",
        "                                        device=DEVICE):\n",
        "    \"\"\"\n",
        "    Compute robust anomaly score from multi-layer features with spatial mask.\n",
        "    \n",
        "    Steps:\n",
        "        - For each layer in feature_layers:\n",
        "            * compute squared difference (t-s)^2\n",
        "            * average over channels -> anomaly map per layer [B, Hf, Wf]\n",
        "            * resize spatial mask to [Hf, Wf] and multiply element-wise\n",
        "        - Upsample each layer anomaly map to the highest spatial resolution among the layers\n",
        "        - Fuse layers (weighted sum)\n",
        "        - For each image in the batch, flatten the fused map and compute a robust score:\n",
        "            * take top-k percentile of anomaly values and average them\n",
        "    \n",
        "    Args:\n",
        "        teacher_feats: Dict[layer_name -> tensor [B, C, Hf, Wf]]\n",
        "        student_feats: Dict[layer_name -> tensor [B, C, Hf, Wf]]\n",
        "        spatial_mask_fullres: Weight map at image resolution [1, 1, H, W]\n",
        "        feature_layers: List of layer names to use\n",
        "        feature_layer_weights: Dict of weights for each layer\n",
        "        topk_percent: Top-k percentile for robust score (e.g. 0.01 = top 1%)\n",
        "        device: Device for computation\n",
        "    \n",
        "    Returns:\n",
        "        scores: Tensor [B] with one scalar anomaly score per image\n",
        "    \"\"\"\n",
        "    # Get fused map\n",
        "    fused = compute_fused_anomaly_map(\n",
        "        teacher_feats, student_feats,\n",
        "        spatial_mask_fullres,\n",
        "        feature_layers=feature_layers,\n",
        "        feature_layer_weights=feature_layer_weights,\n",
        "        device=device\n",
        "    )  # [B, 1, Href, Wref]\n",
        "    \n",
        "    # Robust scalar aggregation: top-k percentile\n",
        "    B, _, Href, Wref = fused.shape\n",
        "    fused_flat = fused.view(B, -1)  # [B, Href*Wref]\n",
        "    \n",
        "    # Compute top-k\n",
        "    k = max(1, int(topk_percent * fused_flat.size(1)))  # e.g. top 1%\n",
        "    topk_vals, _ = torch.topk(fused_flat, k=k, dim=1)\n",
        "    scores = topk_vals.mean(dim=1)  # [B]\n",
        "    \n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelli Teacher & Student\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Teacher(nn.Module):\n",
        "    \"\"\"\n",
        "    Teacher: ResNet18 pre-addestrato su ImageNet (congelato).\n",
        "    Usato per estrarre feature di riferimento multi-layer.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Teacher, self).__init__()\n",
        "        # Carica ResNet18 pre-addestrato\n",
        "        base = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        \n",
        "        # Decomponi ResNet18 in layer separati per estrarre feature multi-layer\n",
        "        self.stem = nn.Sequential(\n",
        "            base.conv1,\n",
        "            base.bn1,\n",
        "            base.relu,\n",
        "            base.maxpool\n",
        "        )\n",
        "        self.layer1 = base.layer1\n",
        "        self.layer2 = base.layer2\n",
        "        self.layer3 = base.layer3\n",
        "        self.layer4 = base.layer4\n",
        "        \n",
        "        # Congela tutti i parametri (no training)\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor [B, 3, H, W]\n",
        "        Returns:\n",
        "            features: Dict con feature maps multi-layer:\n",
        "                - \"layer2\": [B, 128, H/8, W/8]\n",
        "                - \"layer3\": [B, 256, H/16, W/16]\n",
        "                - \"layer4\": [B, 512, H/32, W/32]\n",
        "        \"\"\"\n",
        "        x = self.stem(x)\n",
        "        x1 = self.layer1(x)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "        \n",
        "        return {\n",
        "            \"layer2\": x2,\n",
        "            \"layer3\": x3,\n",
        "            \"layer4\": x4,\n",
        "        }\n",
        "\n",
        "\n",
        "class Student(nn.Module):\n",
        "    \"\"\"\n",
        "    Student: ResNet18 NON pre-addestrato (pesi random).\n",
        "    Addestrato per imitare le feature del Teacher su immagini OK.\n",
        "    Estrae feature multi-layer come il Teacher.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Student, self).__init__()\n",
        "        # Carica ResNet18 SENZA pesi pre-addestrati\n",
        "        base = resnet18(weights=None)\n",
        "        \n",
        "        # Decomponi ResNet18 in layer separati (stessa struttura del Teacher)\n",
        "        self.stem = nn.Sequential(\n",
        "            base.conv1,\n",
        "            base.bn1,\n",
        "            base.relu,\n",
        "            base.maxpool\n",
        "        )\n",
        "        self.layer1 = base.layer1\n",
        "        self.layer2 = base.layer2\n",
        "        self.layer3 = base.layer3\n",
        "        self.layer4 = base.layer4\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor [B, 3, H, W]\n",
        "        Returns:\n",
        "            features: Dict con feature maps multi-layer:\n",
        "                - \"layer2\": [B, 128, H/8, W/8]\n",
        "                - \"layer3\": [B, 256, H/16, W/16]\n",
        "                - \"layer4\": [B, 512, H/32, W/32]\n",
        "        \"\"\"\n",
        "        x = self.stem(x)\n",
        "        x1 = self.layer1(x)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "        \n",
        "        return {\n",
        "            \"layer2\": x2,\n",
        "            \"layer3\": x3,\n",
        "            \"layer4\": x4,\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funzione Training per Connettore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_efficientad_per_connector(connector_name, csv_path=\"data/dataset.csv\",\n",
        "                                     batch_size=32,\n",
        "                                     num_epochs=20,\n",
        "                                     learning_rate=1e-4,\n",
        "                                     device=None):\n",
        "    \"\"\"\n",
        "    Addestra un modello EfficientAD-M per un singolo connettore.\n",
        "    \n",
        "    Args:\n",
        "        connector_name: Nome del connettore (es. 'conn1')\n",
        "        csv_path: Path al CSV del dataset\n",
        "        batch_size: Dimensione del batch\n",
        "        num_epochs: Numero di epoche\n",
        "        learning_rate: Learning rate\n",
        "        device: Device (cuda/cpu)\n",
        "    \n",
        "    Returns:\n",
        "        teacher: Modello Teacher (congelato)\n",
        "        student: Modello Student addestrato\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training EfficientAD-M per {connector_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Trasformazioni (normalizzazione ImageNet per ResNet pre-addestrato)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    # Dataset (solo OK del connettore specificato)\n",
        "    dataset = EfficientADDatasetPerConnector(csv_path, connector_name, transform=transform)\n",
        "    \n",
        "    # DataLoader (ottimizzato per Colab)\n",
        "    train_loader = DataLoader(\n",
        "        dataset, \n",
        "        batch_size=batch_size, \n",
        "        shuffle=True, \n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True if device.type == 'cuda' else False,\n",
        "        prefetch_factor=2,\n",
        "        persistent_workers=False\n",
        "    )\n",
        "    \n",
        "    # Modelli\n",
        "    teacher = Teacher().to(device)\n",
        "    student = Student().to(device)\n",
        "    \n",
        "    # Teacher in modalit√† eval e congelato\n",
        "    teacher.eval()\n",
        "    for param in teacher.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    # Compute spatial mask if not exists\n",
        "    try:\n",
        "        compute_spatial_weight_mask_for_connector(\n",
        "            connector_name, \n",
        "            csv_path=csv_path,\n",
        "            img_size=IMG_SIZE,\n",
        "            save_dir=\"models\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö†Ô∏è  Errore computing spatial mask: {e}\")\n",
        "        print(f\"  Continuo senza spatial mask...\")\n",
        "    \n",
        "    # Load spatial mask at full resolution for training\n",
        "    try:\n",
        "        spatial_mask_fullres = load_spatial_weight_mask(\n",
        "            connector_name,\n",
        "            target_size=(IMG_SIZE, IMG_SIZE),\n",
        "            save_dir=\"models\",\n",
        "            device=device\n",
        "        )  # [1, 1, IMG_SIZE, IMG_SIZE]\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö†Ô∏è  Errore loading spatial mask: {e}\")\n",
        "        print(f\"  Usando mask uniforme...\")\n",
        "        spatial_mask_fullres = torch.ones(1, 1, IMG_SIZE, IMG_SIZE, device=device)\n",
        "    \n",
        "    # Optimizer (solo per Student)\n",
        "    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
        "    \n",
        "    # Training loop with multi-layer loss and spatial mask\n",
        "    print(f\"\\nTraining Student per imitare Teacher su immagini OK (multi-layer + spatial mask)...\")\n",
        "    student.train()\n",
        "    import torch.nn.functional as F\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            images = images.to(device)\n",
        "            \n",
        "            # Feature Teacher (congelato, no grad) - multi-layer dict\n",
        "            with torch.no_grad():\n",
        "                teacher_feats = teacher(images)  # Dict\n",
        "            \n",
        "            # Feature Student (addestrato) - multi-layer dict\n",
        "            student_feats = student(images)  # Dict\n",
        "            \n",
        "            # Multi-layer loss with spatial mask\n",
        "            total_loss = 0.0\n",
        "            for layer_name in FEATURE_LAYERS:\n",
        "                t = teacher_feats[layer_name]  # [B, C, Hf, Wf]\n",
        "                s = student_feats[layer_name]  # [B, C, Hf, Wf]\n",
        "                \n",
        "                # Get layer spatial dimensions\n",
        "                _, _, Hf, Wf = t.shape\n",
        "                \n",
        "                # Resize spatial mask to layer resolution\n",
        "                mask_resized = F.interpolate(\n",
        "                    spatial_mask_fullres,\n",
        "                    size=(Hf, Wf),\n",
        "                    mode='bilinear',\n",
        "                    align_corners=False\n",
        "                )  # [1, 1, Hf, Wf]\n",
        "                \n",
        "                # Compute difference\n",
        "                diff = (t - s) ** 2  # [B, C, Hf, Wf]\n",
        "                \n",
        "                # Apply spatial mask (broadcast over batch and channels)\n",
        "                diff = diff * mask_resized  # [B, C, Hf, Wf]\n",
        "                \n",
        "                # Layer loss (mean over all dimensions)\n",
        "                layer_loss = diff.mean()\n",
        "                \n",
        "                # Weighted sum\n",
        "                layer_weight = FEATURE_LAYER_WEIGHTS.get(layer_name, 1.0)\n",
        "                total_loss += layer_weight * layer_loss\n",
        "            \n",
        "            # Backward solo su Student\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += total_loss.item()\n",
        "        \n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.6f}\")\n",
        "    \n",
        "    # Salva modello Student\n",
        "    models_dir = Path(\"models\")\n",
        "    models_dir.mkdir(exist_ok=True)\n",
        "    model_path = models_dir / f\"efficientad_student_{connector_name}.pth\"\n",
        "    torch.save(student.state_dict(), model_path)\n",
        "    print(f\"\\n‚úÖ Modello Student salvato in: {model_path}\")\n",
        "    \n",
        "    return teacher, student\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_threshold_per_connector(teacher, student, connector_name, csv_path=\"data/dataset.csv\", \n",
        "                                      threshold_multiplier=2.5, device=None):\n",
        "    \"\"\"\n",
        "    Calcola il threshold per anomaly detection per un singolo connettore.\n",
        "    \n",
        "    Threshold = mu + threshold_multiplier * sigma, dove mu e sigma sono media e std\n",
        "    degli anomaly score su tutte le immagini OK del connettore specificato.\n",
        "    \n",
        "    Anomaly score = differenza tra feature Teacher e Student (max su feature map).\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    print(f\"\\nCalcolo threshold per {connector_name}...\")\n",
        "    \n",
        "    # Trasformazioni (stesse del training)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    # Dataset (solo OK del connettore)\n",
        "    dataset = EfficientADDatasetPerConnector(csv_path, connector_name, transform=transform)\n",
        "    \n",
        "    # DataLoader\n",
        "    loader = DataLoader(\n",
        "        dataset, \n",
        "        batch_size=1,  # Batch size 1 per calcolo preciso\n",
        "        shuffle=False,\n",
        "        num_workers=0,  # Evita problemi con multiprocessing\n",
        "        pin_memory=False\n",
        "    )\n",
        "    \n",
        "    # Load spatial mask at full resolution\n",
        "    try:\n",
        "        spatial_mask_fullres = load_spatial_weight_mask(\n",
        "            connector_name,\n",
        "            target_size=(IMG_SIZE, IMG_SIZE),\n",
        "            save_dir=\"models\",\n",
        "            device=device\n",
        "        )  # [1, 1, IMG_SIZE, IMG_SIZE]\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö†Ô∏è  Errore loading spatial mask: {e}\")\n",
        "        print(f\"  Usando mask uniforme...\")\n",
        "        spatial_mask_fullres = torch.ones(1, 1, IMG_SIZE, IMG_SIZE, device=device)\n",
        "    \n",
        "    # Calcola score per tutte le immagini OK usando robust score\n",
        "    scores = []\n",
        "    \n",
        "    teacher.eval()\n",
        "    student.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images in tqdm(loader, desc=f\"Calcolo score {connector_name}\"):\n",
        "            images = images.to(device)\n",
        "            \n",
        "            # Feature Teacher e Student (multi-layer dict)\n",
        "            teacher_feats = teacher(images)  # Dict\n",
        "            student_feats = student(images)  # Dict\n",
        "            \n",
        "            # Compute robust anomaly score\n",
        "            batch_scores = compute_anomaly_score_from_features(\n",
        "                teacher_feats,\n",
        "                student_feats,\n",
        "                spatial_mask_fullres,\n",
        "                feature_layers=FEATURE_LAYERS,\n",
        "                feature_layer_weights=FEATURE_LAYER_WEIGHTS,\n",
        "                topk_percent=TOP_K_PERCENT,\n",
        "                device=device\n",
        "            )  # [B]\n",
        "            \n",
        "            score = batch_scores[0].cpu().item()\n",
        "            scores.append(score)\n",
        "    \n",
        "    scores = np.array(scores)\n",
        "    mu = np.mean(scores)\n",
        "    sigma = np.std(scores)\n",
        "    threshold = mu + threshold_multiplier * sigma\n",
        "    \n",
        "    print(f\"  Score OK - mean: {mu:.6f}, std: {sigma:.6f}\")\n",
        "    print(f\"  Threshold ({threshold_multiplier}*sigma): {threshold:.6f}\")\n",
        "    \n",
        "    # Salva threshold\n",
        "    models_dir = Path(\"models\")\n",
        "    threshold_path = models_dir / f\"efficientad_threshold_{connector_name}.npy\"\n",
        "    np.save(threshold_path, threshold)\n",
        "    print(f\"  ‚úÖ Threshold salvato in: {threshold_path}\")\n",
        "    \n",
        "    return threshold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop - Tutti i Connettori\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training per tutti i 9 connettori\n",
        "connectors = [f\"conn{i}\" for i in range(1, 10)]\n",
        "\n",
        "trained_models = {}\n",
        "\n",
        "for connector_name in connectors:\n",
        "    try:\n",
        "        # Training\n",
        "        teacher, student = train_efficientad_per_connector(\n",
        "            connector_name=connector_name,\n",
        "            csv_path=\"data/dataset.csv\",\n",
        "            batch_size=BATCH_SIZE,\n",
        "            num_epochs=NUM_EPOCHS,\n",
        "            learning_rate=LEARNING_RATE,\n",
        "            device=DEVICE\n",
        "        )\n",
        "        \n",
        "        trained_models[connector_name] = (teacher, student)\n",
        "        \n",
        "        # Calcolo threshold\n",
        "        threshold = calculate_threshold_per_connector(\n",
        "            teacher=teacher,\n",
        "            student=student,\n",
        "            connector_name=connector_name,\n",
        "            csv_path=\"data/dataset.csv\",\n",
        "            threshold_multiplier=THRESHOLD_MULTIPLIER,\n",
        "            device=DEVICE\n",
        "        )\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Errore durante training di {connector_name}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        continue\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"‚úÖ Training completato per {len(trained_models)} connettori\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funzione di Caricamento Modello\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_efficientad_model(connector_name, device=None):\n",
        "    \"\"\"\n",
        "    Carica un modello EfficientAD-M addestrato per un connettore.\n",
        "    Include anche il caricamento della spatial mask.\n",
        "    \n",
        "    Args:\n",
        "        connector_name: Nome del connettore (es. 'conn1')\n",
        "        device: Device (cuda/cpu)\n",
        "    \n",
        "    Returns:\n",
        "        teacher: Modello Teacher (multi-layer)\n",
        "        student: Modello Student (multi-layer)\n",
        "        threshold: Threshold per anomaly detection\n",
        "        spatial_mask_path: Path alla spatial mask (o None se non esiste)\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    models_dir = Path(\"models\")\n",
        "    model_path = models_dir / f\"efficientad_student_{connector_name}.pth\"\n",
        "    threshold_path = models_dir / f\"efficientad_threshold_{connector_name}.npy\"\n",
        "    spatial_mask_path = models_dir / f\"spatial_mask_{connector_name}.npy\"\n",
        "    \n",
        "    if not model_path.exists():\n",
        "        raise FileNotFoundError(f\"Modello non trovato: {model_path}\")\n",
        "    \n",
        "    if not threshold_path.exists():\n",
        "        raise FileNotFoundError(f\"Threshold non trovato: {threshold_path}\")\n",
        "    \n",
        "    # Carica Teacher (sempre lo stesso, pre-addestrato, multi-layer)\n",
        "    teacher = Teacher().to(device)\n",
        "    teacher.eval()\n",
        "    \n",
        "    # Carica Student (multi-layer)\n",
        "    student = Student().to(device)\n",
        "    student.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    student.eval()\n",
        "    \n",
        "    # Carica threshold\n",
        "    threshold = np.load(threshold_path)\n",
        "    \n",
        "    # Check if spatial mask exists\n",
        "    spatial_mask_exists = spatial_mask_path.exists()\n",
        "    \n",
        "    print(f\"‚úÖ Modello EfficientAD-M caricato per {connector_name}\")\n",
        "    print(f\"  Threshold: {threshold:.6f}\")\n",
        "    print(f\"  Spatial mask: {'‚úÖ' if spatial_mask_exists else '‚ùå'}\")\n",
        "    \n",
        "    return teacher, student, threshold, spatial_mask_path if spatial_mask_exists else None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_spatial_mask(connector_name=DEBUG_CONNECTOR, models_dir=\"models\"):\n",
        "    \"\"\"\n",
        "    Load spatial_mask_{connector_name}.npy from models_dir\n",
        "    and show it with matplotlib:\n",
        "    - grayscale image\n",
        "    - with a colorbar\n",
        "    \"\"\"\n",
        "    models_path = Path(models_dir)\n",
        "    mask_path = models_path / f\"spatial_mask_{connector_name}.npy\"\n",
        "    \n",
        "    if not mask_path.exists():\n",
        "        print(f\"‚ùå Spatial mask not found: {mask_path}\")\n",
        "        print(f\"   Run training first to compute the mask.\")\n",
        "        return\n",
        "    \n",
        "    mask = np.load(mask_path)\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(mask, cmap=\"viridis\")\n",
        "    plt.colorbar(label=\"Weight\")\n",
        "    plt.title(f\"Spatial Weight Mask for {connector_name}\")\n",
        "    plt.xlabel(\"Width (pixels)\")\n",
        "    plt.ylabel(\"Height (pixels)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"‚úÖ Spatial mask visualized for {connector_name}\")\n",
        "    print(f\"   Shape: {mask.shape}\")\n",
        "    print(f\"   Weight range: [{mask.min():.3f}, {mask.max():.3f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_average_anomaly_map_for_connector(\n",
        "    connector_name=DEBUG_CONNECTOR,\n",
        "    csv_path=\"data/dataset.csv\",\n",
        "    max_ok_samples=50\n",
        "):\n",
        "    \"\"\"\n",
        "    For the given connector:\n",
        "    - load up to max_ok_samples images with label == \"OK\"\n",
        "    - for each image:\n",
        "        * compute the fused anomaly map (before reducing to a scalar score),\n",
        "          using the EXISTING pipeline: teacher features, student features,\n",
        "          spatial mask, multi-layer fusion\n",
        "        * upsample the fused anomaly map to image resolution\n",
        "    - average all these maps -> average anomaly heatmap\n",
        "    - visualize:\n",
        "        * show the average anomaly map as a heatmap with matplotlib\n",
        "    \"\"\"\n",
        "    import torch.nn.functional as F\n",
        "    \n",
        "    print(f\"üìä Computing average anomaly map for {connector_name}...\")\n",
        "    \n",
        "    # Load model\n",
        "    try:\n",
        "        teacher, student, threshold, spatial_mask_path = load_efficientad_model(connector_name, device=DEVICE)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading model: {e}\")\n",
        "        return\n",
        "    \n",
        "    # Load spatial mask\n",
        "    try:\n",
        "        spatial_mask_fullres = load_spatial_weight_mask(\n",
        "            connector_name,\n",
        "            target_size=(IMG_SIZE, IMG_SIZE),\n",
        "            save_dir=\"models\",\n",
        "            device=DEVICE\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error loading spatial mask: {e}\")\n",
        "        print(f\"   Using uniform mask...\")\n",
        "        spatial_mask_fullres = torch.ones(1, 1, IMG_SIZE, IMG_SIZE, device=DEVICE)\n",
        "    \n",
        "    # Load OK images\n",
        "    df = pd.read_csv(csv_path)\n",
        "    ok_df = df[(df['label'] == 'OK') & (df['connector_name'] == connector_name)].copy()\n",
        "    \n",
        "    if len(ok_df) == 0:\n",
        "        print(f\"‚ùå No OK images found for {connector_name}\")\n",
        "        return\n",
        "    \n",
        "    # Limit to max_ok_samples\n",
        "    ok_df = ok_df.head(max_ok_samples)\n",
        "    print(f\"   Processing {len(ok_df)} OK images...\")\n",
        "    \n",
        "    # Transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    # Accumulate fused maps\n",
        "    teacher.eval()\n",
        "    student.eval()\n",
        "    all_fused_maps = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, row in tqdm(ok_df.iterrows(), total=len(ok_df), desc=\"  Computing maps\"):\n",
        "            image_path = row['image_path']\n",
        "            \n",
        "            try:\n",
        "                # Load and preprocess image\n",
        "                img = Image.open(image_path).convert('RGB')\n",
        "                img_tensor = transform(img).unsqueeze(0).to(DEVICE)\n",
        "                \n",
        "                # Get features\n",
        "                teacher_feats = teacher(img_tensor)\n",
        "                student_feats = student(img_tensor)\n",
        "                \n",
        "                # Compute fused anomaly map\n",
        "                fused_map = compute_fused_anomaly_map(\n",
        "                    teacher_feats,\n",
        "                    student_feats,\n",
        "                    spatial_mask_fullres,\n",
        "                    feature_layers=FEATURE_LAYERS,\n",
        "                    feature_layer_weights=FEATURE_LAYER_WEIGHTS,\n",
        "                    device=DEVICE\n",
        "                )  # [1, 1, Href, Wref]\n",
        "                \n",
        "                # Upsample to image resolution\n",
        "                fused_upsampled = F.interpolate(\n",
        "                    fused_map,\n",
        "                    size=(IMG_SIZE, IMG_SIZE),\n",
        "                    mode='bilinear',\n",
        "                    align_corners=False\n",
        "                )  # [1, 1, IMG_SIZE, IMG_SIZE]\n",
        "                \n",
        "                all_fused_maps.append(fused_upsampled.cpu().numpy())\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ö†Ô∏è  Error processing {image_path}: {e}\")\n",
        "                continue\n",
        "    \n",
        "    if len(all_fused_maps) == 0:\n",
        "        print(f\"‚ùå No valid maps computed\")\n",
        "        return\n",
        "    \n",
        "    # Average all maps\n",
        "    avg_map = np.mean(all_fused_maps, axis=0)[0, 0]  # [IMG_SIZE, IMG_SIZE]\n",
        "    \n",
        "    # Visualize\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(avg_map, cmap=\"jet\")\n",
        "    plt.colorbar(label=\"Average Anomaly Score\")\n",
        "    plt.title(f\"Average Anomaly Map for {connector_name} (OK images, n={len(all_fused_maps)})\")\n",
        "    plt.xlabel(\"Width (pixels)\")\n",
        "    plt.ylabel(\"Height (pixels)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"‚úÖ Average anomaly map computed and visualized\")\n",
        "    print(f\"   Map shape: {avg_map.shape}\")\n",
        "    print(f\"   Score range: [{avg_map.min():.6f}, {avg_map.max():.6f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_example_ok_ko_heatmaps(\n",
        "    connector_name=DEBUG_CONNECTOR,\n",
        "    csv_path=\"data/dataset.csv\",\n",
        "    ko_labels=(\"KO\",),\n",
        "    models_dir=\"models\"\n",
        "):\n",
        "    \"\"\"\n",
        "    - Select one OK image for this connector (label == \"OK\")\n",
        "    - Select one KO image for this connector (label in ko_labels),\n",
        "      ignoring occlusion-related labels (like 'OCCLUSION' / 'PARTIAL OCCLUSION').\n",
        "    - For each selected image:\n",
        "        * load the original RGB image\n",
        "        * compute fused anomaly map with the current pipeline\n",
        "        * upsample the map to the original image resolution\n",
        "        * normalize to [0,1]\n",
        "        * visualize:\n",
        "            - original image\n",
        "            - anomaly heatmap alone\n",
        "            - overlay: original image + semi-transparent anomaly heatmap\n",
        "    \"\"\"\n",
        "    import torch.nn.functional as F\n",
        "    \n",
        "    print(f\"üìä Visualizing OK/KO heatmaps for {connector_name}...\")\n",
        "    \n",
        "    # Load model\n",
        "    try:\n",
        "        teacher, student, threshold, spatial_mask_path = load_efficientad_model(connector_name, device=DEVICE)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading model: {e}\")\n",
        "        return\n",
        "    \n",
        "    # Load spatial mask\n",
        "    try:\n",
        "        spatial_mask_fullres = load_spatial_weight_mask(\n",
        "            connector_name,\n",
        "            target_size=(IMG_SIZE, IMG_SIZE),\n",
        "            save_dir=\"models\",\n",
        "            device=DEVICE\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error loading spatial mask: {e}\")\n",
        "        print(f\"   Using uniform mask...\")\n",
        "        spatial_mask_fullres = torch.ones(1, 1, IMG_SIZE, IMG_SIZE, device=DEVICE)\n",
        "    \n",
        "    # Load dataset\n",
        "    df = pd.read_csv(csv_path)\n",
        "    connector_df = df[df['connector_name'] == connector_name].copy()\n",
        "    \n",
        "    # Select one OK image\n",
        "    ok_df = connector_df[connector_df['label'] == 'OK']\n",
        "    if len(ok_df) == 0:\n",
        "        print(f\"‚ùå No OK images found for {connector_name}\")\n",
        "        return\n",
        "    ok_row = ok_df.iloc[0]\n",
        "    ok_path = ok_row['image_path']\n",
        "    \n",
        "    # Select one KO image (ignore OCCLUSION)\n",
        "    ko_df = connector_df[connector_df['label'].isin(ko_labels)]\n",
        "    if len(ko_df) == 0:\n",
        "        print(f\"‚ö†Ô∏è  No KO images found for {connector_name}, showing only OK\")\n",
        "        ko_path = None\n",
        "    else:\n",
        "        ko_row = ko_df.iloc[0]\n",
        "        ko_path = ko_row['image_path']\n",
        "    \n",
        "    # Transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    teacher.eval()\n",
        "    student.eval()\n",
        "    \n",
        "    def process_image(image_path, label):\n",
        "        \"\"\"Process a single image and return original + anomaly map.\"\"\"\n",
        "        # Load original RGB image\n",
        "        img_original = Image.open(image_path).convert('RGB')\n",
        "        img_array = np.array(img_original)\n",
        "        \n",
        "        # Preprocess for model\n",
        "        img_tensor = transform(img_original).unsqueeze(0).to(DEVICE)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # Get features\n",
        "            teacher_feats = teacher(img_tensor)\n",
        "            student_feats = student(img_tensor)\n",
        "            \n",
        "            # Compute fused anomaly map\n",
        "            fused_map = compute_fused_anomaly_map(\n",
        "                teacher_feats,\n",
        "                student_feats,\n",
        "                spatial_mask_fullres,\n",
        "                feature_layers=FEATURE_LAYERS,\n",
        "                feature_layer_weights=FEATURE_LAYER_WEIGHTS,\n",
        "                device=DEVICE\n",
        "            )  # [1, 1, Href, Wref]\n",
        "            \n",
        "            # Upsample to original image resolution\n",
        "            h_orig, w_orig = img_array.shape[:2]\n",
        "            fused_upsampled = F.interpolate(\n",
        "                fused_map,\n",
        "                size=(h_orig, w_orig),\n",
        "                mode='bilinear',\n",
        "                align_corners=False\n",
        "            )  # [1, 1, h_orig, w_orig]\n",
        "            \n",
        "            # Convert to numpy and normalize to [0, 1]\n",
        "            anomaly_map = fused_upsampled[0, 0].cpu().numpy()\n",
        "            anomaly_map_norm = (anomaly_map - anomaly_map.min()) / (anomaly_map.max() - anomaly_map.min() + 1e-8)\n",
        "        \n",
        "        return img_array, anomaly_map_norm\n",
        "    \n",
        "    # Process OK image\n",
        "    print(f\"  Processing OK image: {Path(ok_path).name}\")\n",
        "    ok_img, ok_map = process_image(ok_path, \"OK\")\n",
        "    \n",
        "    # Process KO image if available\n",
        "    if ko_path:\n",
        "        print(f\"  Processing KO image: {Path(ko_path).name}\")\n",
        "        ko_img, ko_map = process_image(ko_path, \"KO\")\n",
        "    \n",
        "    # Visualize\n",
        "    if ko_path:\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    else:\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    # OK row\n",
        "    axes[0, 0].imshow(ok_img)\n",
        "    axes[0, 0].set_title(f\"OK Image: {Path(ok_path).name}\")\n",
        "    axes[0, 0].axis('off')\n",
        "    \n",
        "    axes[0, 1].imshow(ok_map, cmap=\"jet\")\n",
        "    axes[0, 1].set_title(\"OK Anomaly Heatmap\")\n",
        "    axes[0, 1].axis('off')\n",
        "    \n",
        "    axes[0, 2].imshow(ok_img)\n",
        "    axes[0, 2].imshow(ok_map, cmap=\"jet\", alpha=0.5)\n",
        "    axes[0, 2].set_title(\"OK Overlay\")\n",
        "    axes[0, 2].axis('off')\n",
        "    \n",
        "    # KO row (if available)\n",
        "    if ko_path:\n",
        "        axes[1, 0].imshow(ko_img)\n",
        "        axes[1, 0].set_title(f\"KO Image: {Path(ko_path).name}\")\n",
        "        axes[1, 0].axis('off')\n",
        "        \n",
        "        axes[1, 1].imshow(ko_map, cmap=\"jet\")\n",
        "        axes[1, 1].set_title(\"KO Anomaly Heatmap\")\n",
        "        axes[1, 1].axis('off')\n",
        "        \n",
        "        axes[1, 2].imshow(ko_img)\n",
        "        axes[1, 2].imshow(ko_map, cmap=\"jet\", alpha=0.5)\n",
        "        axes[1, 2].set_title(\"KO Overlay\")\n",
        "        axes[1, 2].axis('off')\n",
        "    \n",
        "    plt.suptitle(f\"Anomaly Heatmaps for {connector_name}\", fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"‚úÖ Heatmaps visualized for {connector_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Debug/Visualization Calls\n",
        "\n",
        "The following functions can be called manually for debugging and interpretation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example debug calls (run manually after training):\n",
        "# \n",
        "# # Visualize spatial mask for DEBUG_CONNECTOR\n",
        "# visualize_spatial_mask()\n",
        "#\n",
        "# # Visualize average anomaly map over OK images\n",
        "# visualize_average_anomaly_map_for_connector()\n",
        "#\n",
        "# # Visualize example OK/KO heatmaps\n",
        "# visualize_example_ok_ko_heatmaps()\n",
        "#\n",
        "# Note: Change DEBUG_CONNECTOR at the top if you want to visualize a different connector\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
