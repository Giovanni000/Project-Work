{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline Training - PCB Connector Recognition\n",
        "\n",
        "Pipeline completa in due step:\n",
        "1. **Classificatore OCCLUSION vs VISIBLE**\n",
        "2. **Autoencoder per anomaly detection su OK visibili**\n",
        "\n",
        "## üìö Struttura Notebook\n",
        "\n",
        "Questa pipeline √® organizzata in notebook separati:\n",
        "- **`step1_occlusion_classifier.ipynb`** - Training classificatore OCCLUSION\n",
        "- **`step2_autoencoder.ipynb`** - Training autoencoder\n",
        "- **`step3_inference.ipynb`** - Funzione di inferenza unica\n",
        "\n",
        "**Utilizzo su Colab:**\n",
        "1. Esegui questo notebook per la preparazione dataset\n",
        "2. Esegui `step1_occlusion_classifier.ipynb` per STEP 1\n",
        "3. Esegui `step2_autoencoder.ipynb` per STEP 2\n",
        "4. Esegui `step3_inference.ipynb` per testare l'inferenza\n",
        "\n",
        "Oppure esegui i notebook in sequenza usando `%run`.\n",
        "\n",
        "## Setup e Dipendenze\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installa dipendenze se necessario\n",
        "# !pip install torch torchvision pandas pillow numpy tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Clona repository GitHub e monta Google Drive per i dati\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Opzione 1: Clona da GitHub (consigliato per sviluppo)\n",
        "# Sostituisci con il tuo repository URL\n",
        "GITHUB_REPO = \"https://github.com/TUO_USERNAME/TUO_REPO.git\"  # ‚ö†Ô∏è MODIFICA QUESTO!\n",
        "REPO_DIR = \"/content/project\"\n",
        "\n",
        "# Clona repository (se non esiste gi√†)\n",
        "if not Path(REPO_DIR).exists():\n",
        "    !git clone {GITHUB_REPO} {REPO_DIR}\n",
        "else:\n",
        "    # Se esiste gi√†, fai pull per aggiornare\n",
        "    os.chdir(REPO_DIR)\n",
        "    !git pull\n",
        "\n",
        "# Cambia directory al repository\n",
        "os.chdir(REPO_DIR)\n",
        "print(f\"Repository directory: {os.getcwd()}\")\n",
        "\n",
        "# Opzione 2: Monta Google Drive solo per i dati (immagini)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path ai dati su Drive\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/Project Work/Data\")\n",
        "print(f\"Data directory: {DATA_ROOT}\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Verifica GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"Memoria GPU disponibile: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 0: Preparazione Dataset\n",
        "\n",
        "Prepara il CSV con i path completi alle immagini.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepara dataset\n",
        "# I path delle immagini devono puntare a Google Drive\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "input_csv = Path(\"features_labeled.csv\")\n",
        "print(f\"Leggendo CSV: {input_csv.absolute()}\")\n",
        "print(f\"CSV esiste: {input_csv.exists()}\")\n",
        "\n",
        "df = pd.read_csv(input_csv)\n",
        "print(f\"\\nCSV caricato: {len(df)} righe\")\n",
        "print(f\"Colonne: {df.columns.tolist()}\")\n",
        "\n",
        "# Verifica colonne necessarie\n",
        "required_cols = ['connector_name', 'filename', 'label']\n",
        "missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "if missing_cols:\n",
        "    print(f\"‚ö†Ô∏è  Colonne mancanti: {missing_cols}\")\n",
        "    print(f\"Colonne disponibili: {df.columns.tolist()}\")\n",
        "\n",
        "df['label_merged'] = df['label'].replace('PARTIAL OCCLUSION', 'OCCLUSION')\n",
        "\n",
        "# Path delle immagini su Google Drive\n",
        "# Verifica prima se esiste gi√† una colonna image_path\n",
        "if 'image_path' in df.columns:\n",
        "    print(\"\\n‚ö†Ô∏è  Trovata colonna 'image_path' esistente\")\n",
        "    print(\"Prime righe:\")\n",
        "    print(df[['image_path', 'connector_name', 'filename']].head())\n",
        "    # Aggiorna i path per puntare a Drive\n",
        "    df['image_path'] = df.apply(\n",
        "        lambda row: f\"/content/drive/MyDrive/Project Work/Data/connectors/{row['connector_name']}/{row['filename']}\",\n",
        "        axis=1\n",
        "    )\n",
        "else:\n",
        "    # Crea path da zero\n",
        "    df['image_path'] = df.apply(\n",
        "        lambda row: f\"/content/drive/MyDrive/Project Work/Data/connectors/{row['connector_name']}/{row['filename']}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "print(f\"\\nVerificando esistenza immagini...\")\n",
        "print(f\"Path Drive: /content/drive/MyDrive/Project Work/Data/connectors/\")\n",
        "print(f\"Drive montato: {Path('/content/drive').exists()}\")\n",
        "\n",
        "# Verifica esistenza immagini\n",
        "existing = []\n",
        "for idx, path in enumerate(df['image_path']):\n",
        "    if Path(path).exists():\n",
        "        existing.append(idx)\n",
        "    elif idx < 5:  # Stampa i primi 5 path non trovati per debug\n",
        "        print(f\"  ‚ùå Non trovato: {path}\")\n",
        "\n",
        "print(f\"\\nImmagini trovate: {len(existing)}/{len(df)}\")\n",
        "\n",
        "if len(existing) == 0:\n",
        "    print(\"\\n‚ö†Ô∏è  PROBLEMA: Nessuna immagine trovata!\")\n",
        "    print(\"\\nPossibili cause:\")\n",
        "    print(\"1. Drive non montato correttamente\")\n",
        "    print(\"2. Path Drive diverso da quello atteso\")\n",
        "    print(\"3. Struttura cartelle diversa su Drive\")\n",
        "    print(\"\\nVerifica manualmente:\")\n",
        "    print(\"  !ls -la /content/drive/MyDrive/Project\\\\ Work/Data/connectors/\")\n",
        "    \n",
        "    # Prova a trovare dove sono le immagini\n",
        "    print(\"\\nCercando immagini su Drive...\")\n",
        "    import subprocess\n",
        "    result = subprocess.run(['find', '/content/drive/MyDrive', '-name', '*.png', '-type', 'f'], \n",
        "                          capture_output=True, text=True, timeout=10)\n",
        "    if result.returncode == 0 and result.stdout:\n",
        "        sample_paths = result.stdout.strip().split('\\n')[:5]\n",
        "        print(f\"Trovate immagini in:\")\n",
        "        for p in sample_paths:\n",
        "            print(f\"  {p}\")\n",
        "            # Estrai il path base\n",
        "            if 'connectors' in p:\n",
        "                base_path = '/'.join(p.split('connectors')[0].split('/')[:-1]) + 'connectors'\n",
        "                print(f\"\\n  Path base suggerito: {base_path}\")\n",
        "                break\n",
        "\n",
        "df_valid = df.iloc[existing].copy() if existing else df.copy()\n",
        "df_valid['label'] = df_valid['label_merged']\n",
        "output_df = df_valid[['image_path', 'label', 'connector_name']].copy()\n",
        "\n",
        "output_csv = Path(\"data/dataset.csv\")\n",
        "output_csv.parent.mkdir(parents=True, exist_ok=True)\n",
        "output_df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset preparato: {len(output_df)} righe\")\n",
        "if len(output_df) > 0:\n",
        "    print(f\"Distribuzione label:\")\n",
        "    print(output_df['label'].value_counts())\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Dataset vuoto! Controlla i path delle immagini.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 1: Training Classificatore OCCLUSION vs VISIBLE\n",
        "\n",
        "Classificatore binario per distinguere immagini occluse da immagini visibili.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 1: Importa e definisci classi e funzioni\n",
        "# Nota: Su Colab, puoi eseguire step1_occlusion_classifier.ipynb prima\n",
        "# oppure importare da qui. Per semplicit√†, includiamo il codice necessario.\n",
        "\n",
        "# Vedi step1_occlusion_classifier.ipynb per il codice completo\n",
        "# Qui assumiamo che tu abbia gi√† eseguito quel notebook o importi le funzioni\n",
        "\n",
        "print(\"‚ö†Ô∏è  Esegui prima step1_occlusion_classifier.ipynb oppure importa le funzioni\")\n",
        "print(\"    Per ora, usa: %run step1_occlusion_classifier.ipynb\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training del classificatore\n",
        "# Se hai eseguito step1_occlusion_classifier.ipynb, la funzione √® gi√† disponibile\n",
        "# Altrimenti, esegui: %run step1_occlusion_classifier.ipynb\n",
        "\n",
        "# model_occ = train_occlusion_classifier(\n",
        "#     csv_path=\"data/dataset.csv\",\n",
        "#     val_fraction=0.2,\n",
        "#     batch_size=32,\n",
        "#     num_epochs=20,\n",
        "#     learning_rate=0.001,\n",
        "#     device=device\n",
        "# )\n",
        "\n",
        "print(\"Esegui step1_occlusion_classifier.ipynb per il training del classificatore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 2: Training Autoencoder per Anomaly Detection\n",
        "\n",
        "Autoencoder addestrato solo su immagini OK per rilevare anomalie.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 2: Importa e definisci classi e funzioni\n",
        "# Vedi step2_autoencoder.ipynb per il codice completo\n",
        "\n",
        "print(\"‚ö†Ô∏è  Esegui step2_autoencoder.ipynb per il training dell'autoencoder\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training dell'autoencoder\n",
        "# Se hai eseguito step2_autoencoder.ipynb, la funzione √® gi√† disponibile\n",
        "# Altrimenti, esegui: %run step2_autoencoder.ipynb\n",
        "\n",
        "# model_ae = train_autoencoder(\n",
        "#     csv_path=\"data/dataset.csv\",\n",
        "#     batch_size=32,\n",
        "#     num_epochs=30,\n",
        "#     learning_rate=0.001,\n",
        "#     device=device\n",
        "# )\n",
        "\n",
        "print(\"Esegui step2_autoencoder.ipynb per il training dell'autoencoder\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcolo threshold\n",
        "# Viene eseguito automaticamente in step2_autoencoder.ipynb\n",
        "\n",
        "print(\"Il threshold viene calcolato automaticamente in step2_autoencoder.ipynb\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 3: Test Inferenza\n",
        "\n",
        "Testa la funzione di inferenza unica su alcune immagini.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 3: Funzione di inferenza\n",
        "# Vedi step3_inference.ipynb per il codice completo\n",
        "\n",
        "print(\"‚ö†Ô∏è  Esegui step3_inference.ipynb per testare l'inferenza\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test inferenza\n",
        "# Esegui step3_inference.ipynb per testare la classificazione\n",
        "\n",
        "print(\"Esegui step3_inference.ipynb per testare l'inferenza su immagini di esempio\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Riepilogo\n",
        "\n",
        "‚úÖ **Modelli salvati in:**\n",
        "- `models/occlusion_cnn.pth` - Classificatore OCCLUSION vs VISIBLE\n",
        "- `models/ae_conv.pth` - Autoencoder\n",
        "- `models/ae_threshold.npy` - Threshold per anomaly detection\n",
        "\n",
        "‚úÖ **Funzione di inferenza:**\n",
        "```python\n",
        "from step3_inference import classify_connector\n",
        "result = classify_connector(\"path/to/image.png\")\n",
        "# Ritorna: \"OK\", \"KO\" o \"OCCLUSION\"\n",
        "```\n",
        "\n",
        "### Download Modelli\n",
        "\n",
        "Dopo il training, scarica i modelli per usarli localmente:\n",
        "```python\n",
        "from google.colab import files\n",
        "files.download('models/occlusion_cnn.pth')\n",
        "files.download('models/ae_conv.pth')\n",
        "files.download('models/ae_threshold.npy')\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
