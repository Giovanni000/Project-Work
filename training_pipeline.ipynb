{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline Training - PCB Connector Recognition\n",
        "\n",
        "Pipeline completa in due step:\n",
        "1. **Classificatore OCCLUSION vs VISIBLE**\n",
        "2. **Autoencoder per anomaly detection su OK visibili**\n",
        "\n",
        "## üìö Struttura Notebook\n",
        "\n",
        "Questa pipeline √® organizzata in notebook separati:\n",
        "- **`step1_occlusion_classifier.ipynb`** - Training classificatore OCCLUSION\n",
        "- **`step2_autoencoder.ipynb`** - Training autoencoder\n",
        "- **`step3_inference.ipynb`** - Funzione di inferenza unica\n",
        "\n",
        "**Utilizzo su Colab:**\n",
        "1. Esegui questo notebook per la preparazione dataset\n",
        "2. Esegui `step1_occlusion_classifier.ipynb` per STEP 1\n",
        "3. Esegui `step2_autoencoder.ipynb` per STEP 2\n",
        "4. Esegui `step3_inference.ipynb` per testare l'inferenza\n",
        "\n",
        "Oppure esegui i notebook in sequenza usando `%run`.\n",
        "\n",
        "## Setup e Dipendenze\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installa dipendenze se necessario\n",
        "# !pip install torch torchvision pandas pillow numpy tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Clona repository GitHub e monta Google Drive per i dati\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Opzione 1: Clona da GitHub (consigliato per sviluppo)\n",
        "# Sostituisci con il tuo repository URL\n",
        "GITHUB_REPO = \"https://github.com/TUO_USERNAME/TUO_REPO.git\"  # ‚ö†Ô∏è MODIFICA QUESTO!\n",
        "REPO_DIR = \"/content/project\"\n",
        "\n",
        "# Clona repository (se non esiste gi√†)\n",
        "if not Path(REPO_DIR).exists():\n",
        "    !git clone {GITHUB_REPO} {REPO_DIR}\n",
        "else:\n",
        "    # Se esiste gi√†, fai pull per aggiornare\n",
        "    os.chdir(REPO_DIR)\n",
        "    !git pull\n",
        "\n",
        "# Cambia directory al repository\n",
        "os.chdir(REPO_DIR)\n",
        "print(f\"Repository directory: {os.getcwd()}\")\n",
        "\n",
        "# Opzione 2: Monta Google Drive solo per i dati (immagini)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path ai dati su Drive\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/Project Work/Data\")\n",
        "print(f\"Data directory: {DATA_ROOT}\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Verifica GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"Memoria GPU disponibile: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 0: Preparazione Dataset\n",
        "\n",
        "Prepara il CSV con i path completi alle immagini.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepara dataset\n",
        "# I path delle immagini devono puntare a Google Drive\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "input_csv = Path(\"features_labeled.csv\")\n",
        "df = pd.read_csv(input_csv)\n",
        "df['label_merged'] = df['label'].replace('PARTIAL OCCLUSION', 'OCCLUSION')\n",
        "\n",
        "# Path delle immagini su Google Drive\n",
        "df['image_path'] = df.apply(\n",
        "    lambda row: f\"/content/drive/MyDrive/Project Work/Data/connectors/{row['connector_name']}/{row['filename']}\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Verifica esistenza immagini\n",
        "existing = [idx for idx, path in enumerate(df['image_path']) if Path(path).exists()]\n",
        "df_valid = df.iloc[existing].copy()\n",
        "df_valid['label'] = df_valid['label_merged']\n",
        "output_df = df_valid[['image_path', 'label', 'connector_name']].copy()\n",
        "\n",
        "output_csv = Path(\"data/dataset.csv\")\n",
        "output_csv.parent.mkdir(parents=True, exist_ok=True)\n",
        "output_df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"‚úÖ Dataset preparato: {len(output_df)} righe\")\n",
        "print(f\"Distribuzione label:\")\n",
        "print(output_df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 1: Training Classificatore OCCLUSION vs VISIBLE\n",
        "\n",
        "Classificatore binario per distinguere immagini occluse da immagini visibili.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 1: Importa e definisci classi e funzioni\n",
        "# Nota: Su Colab, puoi eseguire step1_occlusion_classifier.ipynb prima\n",
        "# oppure importare da qui. Per semplicit√†, includiamo il codice necessario.\n",
        "\n",
        "# Vedi step1_occlusion_classifier.ipynb per il codice completo\n",
        "# Qui assumiamo che tu abbia gi√† eseguito quel notebook o importi le funzioni\n",
        "\n",
        "print(\"‚ö†Ô∏è  Esegui prima step1_occlusion_classifier.ipynb oppure importa le funzioni\")\n",
        "print(\"    Per ora, usa: %run step1_occlusion_classifier.ipynb\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training del classificatore\n",
        "# Se hai eseguito step1_occlusion_classifier.ipynb, la funzione √® gi√† disponibile\n",
        "# Altrimenti, esegui: %run step1_occlusion_classifier.ipynb\n",
        "\n",
        "# model_occ = train_occlusion_classifier(\n",
        "#     csv_path=\"data/dataset.csv\",\n",
        "#     val_fraction=0.2,\n",
        "#     batch_size=32,\n",
        "#     num_epochs=20,\n",
        "#     learning_rate=0.001,\n",
        "#     device=device\n",
        "# )\n",
        "\n",
        "print(\"Esegui step1_occlusion_classifier.ipynb per il training del classificatore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 2: Training Autoencoder per Anomaly Detection\n",
        "\n",
        "Autoencoder addestrato solo su immagini OK per rilevare anomalie.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 2: Importa e definisci classi e funzioni\n",
        "# Vedi step2_autoencoder.ipynb per il codice completo\n",
        "\n",
        "print(\"‚ö†Ô∏è  Esegui step2_autoencoder.ipynb per il training dell'autoencoder\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training dell'autoencoder\n",
        "# Se hai eseguito step2_autoencoder.ipynb, la funzione √® gi√† disponibile\n",
        "# Altrimenti, esegui: %run step2_autoencoder.ipynb\n",
        "\n",
        "# model_ae = train_autoencoder(\n",
        "#     csv_path=\"data/dataset.csv\",\n",
        "#     batch_size=32,\n",
        "#     num_epochs=30,\n",
        "#     learning_rate=0.001,\n",
        "#     device=device\n",
        "# )\n",
        "\n",
        "print(\"Esegui step2_autoencoder.ipynb per il training dell'autoencoder\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcolo threshold\n",
        "# Viene eseguito automaticamente in step2_autoencoder.ipynb\n",
        "\n",
        "print(\"Il threshold viene calcolato automaticamente in step2_autoencoder.ipynb\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 3: Test Inferenza\n",
        "\n",
        "Testa la funzione di inferenza unica su alcune immagini.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 3: Funzione di inferenza\n",
        "# Vedi step3_inference.ipynb per il codice completo\n",
        "\n",
        "print(\"‚ö†Ô∏è  Esegui step3_inference.ipynb per testare l'inferenza\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test inferenza\n",
        "# Esegui step3_inference.ipynb per testare la classificazione\n",
        "\n",
        "print(\"Esegui step3_inference.ipynb per testare l'inferenza su immagini di esempio\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Riepilogo\n",
        "\n",
        "‚úÖ **Modelli salvati in:**\n",
        "- `models/occlusion_cnn.pth` - Classificatore OCCLUSION vs VISIBLE\n",
        "- `models/ae_conv.pth` - Autoencoder\n",
        "- `models/ae_threshold.npy` - Threshold per anomaly detection\n",
        "\n",
        "‚úÖ **Funzione di inferenza:**\n",
        "```python\n",
        "from step3_inference import classify_connector\n",
        "result = classify_connector(\"path/to/image.png\")\n",
        "# Ritorna: \"OK\", \"KO\" o \"OCCLUSION\"\n",
        "```\n",
        "\n",
        "### Download Modelli\n",
        "\n",
        "Dopo il training, scarica i modelli per usarli localmente:\n",
        "```python\n",
        "from google.colab import files\n",
        "files.download('models/occlusion_cnn.pth')\n",
        "files.download('models/ae_conv.pth')\n",
        "files.download('models/ae_threshold.npy')\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
