{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 2: Autoencoder per Anomaly Detection\n",
        "\n",
        "Autoencoder convoluzionale addestrato solo su immagini OK (visibili e corrette).\n",
        "Calcola threshold basato su errore di ricostruzione per rilevare anomalie.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Clona repository GitHub e monta Google Drive per i dati\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Opzione 1: Clona da GitHub (consigliato per sviluppo)\n",
        "# Sostituisci con il tuo repository URL\n",
        "GITHUB_REPO = \"https://github.com/Giovanni000/Project-Work.git\"  # ‚ö†Ô∏è MODIFICA QUESTO!\n",
        "REPO_DIR = \"/content/project\"\n",
        "\n",
        "# Clona repository (se non esiste gi√†)\n",
        "if not Path(REPO_DIR).exists():\n",
        "    !git clone {GITHUB_REPO} {REPO_DIR}\n",
        "\n",
        "# Cambia directory al repository\n",
        "os.chdir(REPO_DIR)\n",
        "print(f\"Repository directory: {os.getcwd()}\")\n",
        "\n",
        "# Opzione 2: Monta Google Drive solo per i dati (immagini)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path ai dati su Drive\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/Project Work/Data\")\n",
        "print(f\"Data directory: {DATA_ROOT}\")\n",
        "\n",
        "# ‚ö†Ô∏è IMPORTANTE: Le immagini su Drive sono LENTE da caricare durante il training!\n",
        "# Se il training √® troppo lento, considera di copiare le immagini in locale prima\n",
        "\n",
        "# Import necessari\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Seed per riproducibilit√†\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Verifica device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU: {gpu_name}\")\n",
        "    print(f\"VRAM: {gpu_memory:.1f} GB\")\n",
        "    if \"T4\" in gpu_name:\n",
        "        print(\"‚úÖ Tesla T4 rilevata - Parametri ottimizzati per questa GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Class (solo OK)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AEDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset PyTorch per autoencoder.\n",
        "    Contiene solo immagini con label == \"OK\".\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, csv_path, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_path: Path al CSV con colonne 'image_path' e 'label'\n",
        "            transform: Trasformazioni da applicare alle immagini\n",
        "        \"\"\"\n",
        "        df = pd.read_csv(csv_path)\n",
        "        # Filtra solo OK\n",
        "        self.df = df[df['label'] == 'OK'].copy().reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        \n",
        "        print(f\"Dataset AE caricato: {len(self.df)} immagini OK\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image_path = row['image_path']\n",
        "        \n",
        "        # Carica immagine (ottimizzato: evita lazy loading)\n",
        "        try:\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            # Forza il caricamento completo dell'immagine\n",
        "            image.load()\n",
        "        except Exception as e:\n",
        "            print(f\"Errore caricamento {image_path}: {e}\")\n",
        "            # Fallback: immagine nera\n",
        "            image = Image.new('RGB', (128, 128), (0, 0, 0))\n",
        "        \n",
        "        # Applica trasformazioni\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modello Autoencoder Convoluzionale\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoencoder convoluzionale per anomaly detection.\n",
        "    \n",
        "    Encoder: 3 conv2d con stride=2 (3‚Üí16‚Üí32‚Üí64 canali)\n",
        "    Decoder: 3 convtranspose2d simmetriche (64‚Üí32‚Üí16‚Üí3 canali)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(ConvAE, self).__init__()\n",
        "        \n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            # 128x128x3 -> 64x64x16\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            # 64x64x16 -> 32x32x32\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            # 32x32x32 -> 16x16x64\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            # 16x16x64 -> 32x32x32\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            # 32x32x32 -> 64x64x16\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            # 64x64x16 -> 128x128x3\n",
        "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()  # Output in [0, 1]\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° Ottimizzazione: Copia Immagini in Locale (OPZIONALE)\n",
        "\n",
        "**Se il training √® troppo lento**, copia le immagini da Drive in locale prima del training.\n",
        "Questo accelera drasticamente il caricamento durante il training.\n",
        "\n",
        "**Nota:** Richiede spazio su disco (~500MB-1GB per ~2853 immagini 128x128).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚ö° IMPORTANTE: Copia immagini in locale per velocizzare il training\n",
        "# Il training √® lento perch√© legge ogni immagine da Google Drive (latenza alta)\n",
        "# Copiando in locale, il training diventa 10-20x pi√π veloce!\n",
        "\n",
        "COPY_TO_LOCAL = True  # Cambia a False se vuoi usare Drive direttamente (LENTO!)\n",
        "\n",
        "if COPY_TO_LOCAL:\n",
        "    import shutil\n",
        "    from tqdm import tqdm\n",
        "    \n",
        "    LOCAL_DATA_DIR = Path(\"/content/local_data\")\n",
        "    LOCAL_DATA_DIR.mkdir(exist_ok=True)\n",
        "    \n",
        "    # Leggi CSV per ottenere tutti i path\n",
        "    csv_path = Path(\"data/dataset.csv\")\n",
        "    if csv_path.exists():\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f\"üì¶ Copiando {len(df)} immagini da Drive in locale...\")\n",
        "        print(\"   Questo richiede ~2-5 minuti, ma accelera il training di 10-20x!\")\n",
        "        print(\"   \" + \"=\"*60)\n",
        "        \n",
        "        copied = 0\n",
        "        skipped = 0\n",
        "        errors = 0\n",
        "        \n",
        "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Copia immagini\"):\n",
        "            src_path = Path(row['image_path'])\n",
        "            # Mantieni struttura: connector_name/filename\n",
        "            rel_path = Path(row['connector_name']) / row['filename']\n",
        "            dst_path = LOCAL_DATA_DIR / rel_path\n",
        "            \n",
        "            if dst_path.exists():\n",
        "                skipped += 1\n",
        "            else:\n",
        "                dst_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "                try:\n",
        "                    shutil.copy2(src_path, dst_path)\n",
        "                    copied += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Errore copia {src_path}: {e}\")\n",
        "                    errors += 1\n",
        "        \n",
        "        print(\"   \" + \"=\"*60)\n",
        "        print(f\"‚úÖ Copiate {copied} immagini nuove\")\n",
        "        print(f\"‚è≠Ô∏è  Saltate {skipped} immagini gi√† presenti\")\n",
        "        if errors > 0:\n",
        "            print(f\"‚ùå Errori: {errors}\")\n",
        "        \n",
        "        # Aggiorna i path nel CSV per puntare a locale\n",
        "        print(\"\\nüîÑ Aggiornamento path nel CSV...\")\n",
        "        df['image_path'] = df.apply(\n",
        "            lambda row: str(LOCAL_DATA_DIR / row['connector_name'] / row['filename']),\n",
        "            axis=1\n",
        "        )\n",
        "        df.to_csv(csv_path, index=False)\n",
        "        print(f\"‚úÖ CSV aggiornato: i path ora puntano a {LOCAL_DATA_DIR}\")\n",
        "        print(f\"\\nüöÄ Ora il training sar√† MOLTO pi√π veloce!\")\n",
        "        \n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  data/dataset.csv non trovato. Esegui prima la preparazione del dataset.\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è  Copia locale disabilitata.\")\n",
        "    print(\"‚ö†Ô∏è  ATTENZIONE: Il training sar√† LENTO (10-20x pi√π lento) perch√© legge da Drive!\")\n",
        "    print(\"   Imposta COPY_TO_LOCAL = True per velocizzare.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_autoencoder(csv_path=\"data/dataset.csv\",\n",
        "                     batch_size=32,\n",
        "                     num_epochs=30,\n",
        "                     learning_rate=0.001,\n",
        "                     device=None):\n",
        "    \"\"\"\n",
        "    Training loop per l'autoencoder.\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    print(f\"Device: {device}\")\n",
        "    \n",
        "    # Trasformazioni per le immagini (normalizzazione in [0,1])\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),  # Gi√† in [0, 1]\n",
        "    ])\n",
        "    \n",
        "    # Crea dataset (solo OK)\n",
        "    dataset = AEDataset(csv_path, transform=transform)\n",
        "    \n",
        "    # DataLoader (ottimizzato per Colab)\n",
        "    # num_workers=0 su Colab spesso √® pi√π veloce (evita problemi di serializzazione)\n",
        "    # pin_memory=True accelera il trasferimento CPU->GPU\n",
        "    train_loader = DataLoader(\n",
        "        dataset, \n",
        "        batch_size=batch_size, \n",
        "        shuffle=True, \n",
        "        num_workers=0,  # 0 su Colab √® pi√π veloce\n",
        "        pin_memory=True if device.type == 'cuda' else False,\n",
        "        persistent_workers=False\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nDataset: {len(dataset)} immagini OK\")\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "    print(f\"Numero di batch: {len(train_loader)}\")\n",
        "    \n",
        "    # Modello\n",
        "    model = ConvAE().to(device)\n",
        "    print(f\"\\nModello creato. Parametri totali: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    # Loss e optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        "    # Training loop\n",
        "    print(f\"\\nInizio training per {num_epochs} epoch...\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        \n",
        "        for images in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            images = images.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            reconstructed = model(images)\n",
        "            loss = criterion(reconstructed, images)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}: Reconstruction Loss = {avg_loss:.6f}\")\n",
        "        print(\"-\" * 60)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Training completato!\")\n",
        "    \n",
        "    # Salva modello\n",
        "    models_dir = Path(\"models\")\n",
        "    models_dir.mkdir(exist_ok=True)\n",
        "    model_path = models_dir / \"ae_conv.pth\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"   Modello salvato in: {model_path}\")\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Esegui Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training dell'autoencoder\n",
        "# ‚ö° Ottimizzazioni per velocit√†:\n",
        "# - batch_size=64: pi√π veloce su GPU (puoi aumentare fino a 128 se hai memoria)\n",
        "model_ae = train_autoencoder(\n",
        "    csv_path=\"data/dataset.csv\",\n",
        "    batch_size=64,  # Aumentato da 32 per velocizzare (usa 128 se hai memoria GPU)\n",
        "    num_epochs=30,\n",
        "    learning_rate=0.001,\n",
        "    device=device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calcolo Threshold\n",
        "\n",
        "Calcola il threshold per anomaly detection basato su errore di ricostruzione.\n",
        "Threshold = mu + 3*sigma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_threshold(model, csv_path=\"data/dataset.csv\", device=None):\n",
        "    \"\"\"\n",
        "    Calcola il threshold per anomaly detection basato su errore di ricostruzione.\n",
        "    \n",
        "    Threshold = mu + 3*sigma, dove mu e sigma sono media e std degli errori\n",
        "    di ricostruzione su tutto il dataset di training (solo OK).\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    print(\"\\nCalcolo threshold su dataset di training...\")\n",
        "    \n",
        "    # Trasformazioni\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    \n",
        "    # Dataset (solo OK)\n",
        "    dataset = AEDataset(csv_path, transform=transform)\n",
        "    loader = DataLoader(\n",
        "        dataset, \n",
        "        batch_size=32, \n",
        "        shuffle=False, \n",
        "        num_workers=0,  # 0 su Colab √® pi√π veloce\n",
        "        pin_memory=True if device.type == 'cuda' else False,\n",
        "        persistent_workers=False\n",
        "    )\n",
        "    \n",
        "    model.eval()\n",
        "    errors = []\n",
        "    criterion = nn.MSELoss(reduction='none')  # Per avere errore per ogni pixel\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images in tqdm(loader, desc=\"Calcolo errori\"):\n",
        "            images = images.to(device)\n",
        "            reconstructed = model(images)\n",
        "            \n",
        "            # Errore per ogni immagine nel batch\n",
        "            # Shape: [batch, 3, 128, 128]\n",
        "            batch_errors = criterion(reconstructed, images)\n",
        "            # Media su canali e spaziale: [batch]\n",
        "            batch_errors = batch_errors.mean(dim=(1, 2, 3))\n",
        "            \n",
        "            errors.extend(batch_errors.cpu().numpy())\n",
        "    \n",
        "    errors = np.array(errors)\n",
        "    mu = np.mean(errors)\n",
        "    sigma = np.std(errors)\n",
        "    threshold = mu + 3 * sigma\n",
        "    \n",
        "    print(f\"\\nStatistiche errori di ricostruzione:\")\n",
        "    print(f\"  Media (mu): {mu:.6f}\")\n",
        "    print(f\"  Std (sigma): {sigma:.6f}\")\n",
        "    print(f\"  Min: {errors.min():.6f}\")\n",
        "    print(f\"  Max: {errors.max():.6f}\")\n",
        "    print(f\"\\nThreshold (mu + 3*sigma): {threshold:.6f}\")\n",
        "    \n",
        "    # Salva threshold\n",
        "    models_dir = Path(\"models\")\n",
        "    models_dir.mkdir(exist_ok=True)\n",
        "    threshold_path = models_dir / \"ae_threshold.npy\"\n",
        "    np.save(threshold_path, threshold)\n",
        "    print(f\"  Threshold salvato in: {threshold_path}\")\n",
        "    \n",
        "    return threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcola il threshold\n",
        "threshold = calculate_threshold(model_ae, csv_path=\"data/dataset.csv\", device=device)\n",
        "print(f\"\\n‚úÖ Threshold calcolato: {threshold:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funzione Helper per Caricare Modello e Threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_ae_and_threshold(device=None):\n",
        "    \"\"\"\n",
        "    Carica l'autoencoder addestrato e il threshold.\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # Carica modello\n",
        "    model = ConvAE().to(device)\n",
        "    model_path = Path(\"models/ae_conv.pth\")\n",
        "    \n",
        "    if not model_path.exists():\n",
        "        raise FileNotFoundError(f\"Modello non trovato: {model_path}\")\n",
        "    \n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    \n",
        "    # Carica threshold\n",
        "    threshold_path = Path(\"models/ae_threshold.npy\")\n",
        "    if not threshold_path.exists():\n",
        "        raise FileNotFoundError(f\"Threshold non trovato: {threshold_path}\")\n",
        "    \n",
        "    threshold = np.load(threshold_path)\n",
        "    \n",
        "    return model, threshold\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
