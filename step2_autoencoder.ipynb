{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STEP 2: Autoencoder per Anomaly Detection\n",
        "\n",
        "Autoencoder convoluzionale addestrato solo su immagini OK (visibili e corrette).\n",
        "Calcola threshold basato su errore di ricostruzione per rilevare anomalie.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Clona repository GitHub e monta Google Drive per i dati\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Opzione 1: Clona da GitHub (consigliato per sviluppo)\n",
        "# Sostituisci con il tuo repository URL\n",
        "GITHUB_REPO = \"https://github.com/Giovanni000/Project-Work.git\"  # ⚠️ MODIFICA QUESTO!\n",
        "REPO_DIR = \"/content/project\"\n",
        "\n",
        "# Clona repository (se non esiste già)\n",
        "if not Path(REPO_DIR).exists():\n",
        "    !git clone {GITHUB_REPO} {REPO_DIR}\n",
        "\n",
        "# Cambia directory al repository\n",
        "os.chdir(REPO_DIR)\n",
        "print(f\"Repository directory: {os.getcwd()}\")\n",
        "\n",
        "# Opzione 2: Monta Google Drive solo per i dati (immagini)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path ai dati su Drive\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/Project Work/Data\")\n",
        "print(f\"Data directory: {DATA_ROOT}\")\n",
        "\n",
        "# Import necessari\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Seed per riproducibilità\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Verifica device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Class (solo OK)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AEDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset PyTorch per autoencoder.\n",
        "    Contiene solo immagini con label == \"OK\".\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, csv_path, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_path: Path al CSV con colonne 'image_path' e 'label'\n",
        "            transform: Trasformazioni da applicare alle immagini\n",
        "        \"\"\"\n",
        "        df = pd.read_csv(csv_path)\n",
        "        # Filtra solo OK\n",
        "        self.df = df[df['label'] == 'OK'].copy().reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        \n",
        "        print(f\"Dataset AE caricato: {len(self.df)} immagini OK\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image_path = row['image_path']\n",
        "        \n",
        "        # Carica immagine\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        \n",
        "        # Applica trasformazioni\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modello Autoencoder Convoluzionale\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoencoder convoluzionale per anomaly detection.\n",
        "    \n",
        "    Encoder: 3 conv2d con stride=2 (3→16→32→64 canali)\n",
        "    Decoder: 3 convtranspose2d simmetriche (64→32→16→3 canali)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(ConvAE, self).__init__()\n",
        "        \n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            # 128x128x3 -> 64x64x16\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            # 64x64x16 -> 32x32x32\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            # 32x32x32 -> 16x16x64\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            # 16x16x64 -> 32x32x32\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            # 32x32x32 -> 64x64x16\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            # 64x64x16 -> 128x128x3\n",
        "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()  # Output in [0, 1]\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_autoencoder(csv_path=\"data/dataset.csv\",\n",
        "                     batch_size=32,\n",
        "                     num_epochs=30,\n",
        "                     learning_rate=0.001,\n",
        "                     device=None):\n",
        "    \"\"\"\n",
        "    Training loop per l'autoencoder.\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    print(f\"Device: {device}\")\n",
        "    \n",
        "    # Trasformazioni per le immagini (normalizzazione in [0,1])\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),  # Già in [0, 1]\n",
        "    ])\n",
        "    \n",
        "    # Crea dataset (solo OK)\n",
        "    dataset = AEDataset(csv_path, transform=transform)\n",
        "    \n",
        "    # DataLoader\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    \n",
        "    print(f\"\\nDataset: {len(dataset)} immagini OK\")\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "    print(f\"Numero di batch: {len(train_loader)}\")\n",
        "    \n",
        "    # Modello\n",
        "    model = ConvAE().to(device)\n",
        "    print(f\"\\nModello creato. Parametri totali: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    # Loss e optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        "    # Training loop\n",
        "    print(f\"\\nInizio training per {num_epochs} epoch...\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        \n",
        "        for images in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            images = images.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            reconstructed = model(images)\n",
        "            loss = criterion(reconstructed, images)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}: Reconstruction Loss = {avg_loss:.6f}\")\n",
        "        print(\"-\" * 60)\n",
        "    \n",
        "    print(f\"\\n✅ Training completato!\")\n",
        "    \n",
        "    # Salva modello\n",
        "    models_dir = Path(\"models\")\n",
        "    models_dir.mkdir(exist_ok=True)\n",
        "    model_path = models_dir / \"ae_conv.pth\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"   Modello salvato in: {model_path}\")\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Esegui Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training dell'autoencoder\n",
        "model_ae = train_autoencoder(\n",
        "    csv_path=\"data/dataset.csv\",\n",
        "    batch_size=32,\n",
        "    num_epochs=30,\n",
        "    learning_rate=0.001,\n",
        "    device=device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calcolo Threshold\n",
        "\n",
        "Calcola il threshold per anomaly detection basato su errore di ricostruzione.\n",
        "Threshold = mu + 3*sigma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_threshold(model, csv_path=\"data/dataset.csv\", device=None):\n",
        "    \"\"\"\n",
        "    Calcola il threshold per anomaly detection basato su errore di ricostruzione.\n",
        "    \n",
        "    Threshold = mu + 3*sigma, dove mu e sigma sono media e std degli errori\n",
        "    di ricostruzione su tutto il dataset di training (solo OK).\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    print(\"\\nCalcolo threshold su dataset di training...\")\n",
        "    \n",
        "    # Trasformazioni\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    \n",
        "    # Dataset (solo OK)\n",
        "    dataset = AEDataset(csv_path, transform=transform)\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "    \n",
        "    model.eval()\n",
        "    errors = []\n",
        "    criterion = nn.MSELoss(reduction='none')  # Per avere errore per ogni pixel\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images in tqdm(loader, desc=\"Calcolo errori\"):\n",
        "            images = images.to(device)\n",
        "            reconstructed = model(images)\n",
        "            \n",
        "            # Errore per ogni immagine nel batch\n",
        "            # Shape: [batch, 3, 128, 128]\n",
        "            batch_errors = criterion(reconstructed, images)\n",
        "            # Media su canali e spaziale: [batch]\n",
        "            batch_errors = batch_errors.mean(dim=(1, 2, 3))\n",
        "            \n",
        "            errors.extend(batch_errors.cpu().numpy())\n",
        "    \n",
        "    errors = np.array(errors)\n",
        "    mu = np.mean(errors)\n",
        "    sigma = np.std(errors)\n",
        "    threshold = mu + 3 * sigma\n",
        "    \n",
        "    print(f\"\\nStatistiche errori di ricostruzione:\")\n",
        "    print(f\"  Media (mu): {mu:.6f}\")\n",
        "    print(f\"  Std (sigma): {sigma:.6f}\")\n",
        "    print(f\"  Min: {errors.min():.6f}\")\n",
        "    print(f\"  Max: {errors.max():.6f}\")\n",
        "    print(f\"\\nThreshold (mu + 3*sigma): {threshold:.6f}\")\n",
        "    \n",
        "    # Salva threshold\n",
        "    models_dir = Path(\"models\")\n",
        "    models_dir.mkdir(exist_ok=True)\n",
        "    threshold_path = models_dir / \"ae_threshold.npy\"\n",
        "    np.save(threshold_path, threshold)\n",
        "    print(f\"  Threshold salvato in: {threshold_path}\")\n",
        "    \n",
        "    return threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcola il threshold\n",
        "threshold = calculate_threshold(model_ae, csv_path=\"data/dataset.csv\", device=device)\n",
        "print(f\"\\n✅ Threshold calcolato: {threshold:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funzione Helper per Caricare Modello e Threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_ae_and_threshold(device=None):\n",
        "    \"\"\"\n",
        "    Carica l'autoencoder addestrato e il threshold.\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # Carica modello\n",
        "    model = ConvAE().to(device)\n",
        "    model_path = Path(\"models/ae_conv.pth\")\n",
        "    \n",
        "    if not model_path.exists():\n",
        "        raise FileNotFoundError(f\"Modello non trovato: {model_path}\")\n",
        "    \n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    \n",
        "    # Carica threshold\n",
        "    threshold_path = Path(\"models/ae_threshold.npy\")\n",
        "    if not threshold_path.exists():\n",
        "        raise FileNotFoundError(f\"Threshold non trovato: {threshold_path}\")\n",
        "    \n",
        "    threshold = np.load(threshold_path)\n",
        "    \n",
        "    return model, threshold\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
