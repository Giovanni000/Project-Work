{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Inferenza Locale (Mac/Local)\n",
    "\n",
    "Versione locale senza dipendenze Colab.\n",
    "\n",
    "**Pipeline:**\n",
    "1. STEP 1 - Occlusione: Verifica se l'immagine è occlusa → se sì, ritorna \"OCCLUSION\"\n",
    "2. STEP 2 - Anomaly Detection: Se visibile, verifica se è anomalo → se errore > threshold → \"KO\", altrimenti \"OK\"\n",
    "\n",
    "**Nota:** L'inferenza è veloce anche su CPU (~0.1-0.5 sec per immagine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup locale (Mac/Local)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Assicurati di essere nella directory del progetto\n",
    "# Se esegui da Jupyter, imposta il path corretto\n",
    "PROJECT_ROOT = Path.cwd()  # Modifica se necessario\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Device: CPU è sufficiente per l'inferenza (veloce anche senza GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cpu':\n",
    "    print(\"ℹ️  Usando CPU - l'inferenza è veloce (~0.1-0.5 sec per immagine)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizione Classi Modelli\n",
    "\n",
    "Definiamo le classi dei modelli per poterli caricare (step3 è autonomo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione classe OcclusionCNN (da step1)\n",
    "class OcclusionCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN semplice per classificazione binaria OCCLUSION vs VISIBLE.\n",
    "    \n",
    "    Architettura:\n",
    "    - 3 layer convoluzionali con pooling\n",
    "    - 2 layer fully connected\n",
    "    - Output: 2 classi (OCCLUSION, VISIBLE)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(OcclusionCNN, self).__init__()\n",
    "        \n",
    "        # Encoder convoluzionale\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # 128x128 -> 64x64\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 64x64 -> 32x32\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)  # 32x32 -> 16x16\n",
    "        \n",
    "        # Fully connected\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 2)  # 2 classi: OCCLUSION, VISIBLE\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convoluzioni\n",
    "        x = self.pool1(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(self.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Definizione classe ConvAE (da step2)\n",
    "class ConvAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder convoluzionale per anomaly detection.\n",
    "    \n",
    "    Encoder: 3 conv2d con stride=2 (3→16→32→64 canali)\n",
    "    Decoder: 3 convtranspose2d simmetriche (64→32→16→3 canali)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 128x128x3 -> 64x64x16\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # 64x64x16 -> 32x32x32\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # 32x32x32 -> 16x16x64\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            # 16x16x64 -> 32x32x32\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # 32x32x32 -> 64x64x16\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # 64x64x16 -> 128x128x3\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  # Output in [0, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "# Funzioni helper per caricare i modelli\n",
    "def load_occlusion_model(device=None):\n",
    "    \"\"\"Carica il modello classificatore OCCLUSION.\"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = OcclusionCNN().to(device)\n",
    "    model_path = Path(\"models/occlusion_cnn.pth\")\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        raise FileNotFoundError(f\"Modello non trovato: {model_path}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_ae_and_threshold(device=None):\n",
    "    \"\"\"Carica l'autoencoder e il threshold.\"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = ConvAE().to(device)\n",
    "    model_path = Path(\"models/ae_conv.pth\")\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        raise FileNotFoundError(f\"Modello non trovato: {model_path}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    threshold_path = Path(\"models/ae_threshold.npy\")\n",
    "    if not threshold_path.exists():\n",
    "        raise FileNotFoundError(f\"Threshold non trovato: {threshold_path}\")\n",
    "    \n",
    "    threshold = np.load(threshold_path)\n",
    "    return model, threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzioni di Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, device=None):\n",
    "    \"\"\"\n",
    "    Preprocessa un'immagine per l'inferenza (classificatore OCCLUSION).\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Trasformazioni (stesse del training)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Carica e preprocessa\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image)\n",
    "    image_tensor = image_tensor.unsqueeze(0)  # Aggiungi dimensione batch\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "def preprocess_image_for_ae(image_path, device=None):\n",
    "    \"\"\"\n",
    "    Preprocessa un'immagine per l'autoencoder (senza normalizzazione ImageNet).\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Trasformazioni (stesse del training AE)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),  # Già in [0, 1]\n",
    "    ])\n",
    "    \n",
    "    # Carica e preprocessa\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image)\n",
    "    image_tensor = image_tensor.unsqueeze(0)  # Aggiungi dimensione batch\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    return image_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzione di Classificazione Principale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_connector(image_path, device=None):\n",
    "    \"\"\"\n",
    "    Classifica un connettore come \"OK\", \"KO\" o \"OCCLUSION\".\n",
    "    \n",
    "    Pipeline:\n",
    "    1. STEP 1 - Occlusione: Verifica se l'immagine è occlusa\n",
    "       - Se occlusa → ritorna \"OCCLUSION\"\n",
    "    2. STEP 2 - Anomaly Detection: Se visibile, verifica se è anomalo\n",
    "       - Se errore ricostruzione > threshold → ritorna \"KO\"\n",
    "       - Altrimenti → ritorna \"OK\"\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path all'immagine del connettore\n",
    "        device: Device (cuda/cpu)\n",
    "    \n",
    "    Returns:\n",
    "        str: \"OK\", \"KO\" o \"OCCLUSION\"\n",
    "        \n",
    "    Note:\n",
    "        - \"OCCLUSION\" = immagine non leggibile (cavi o altro coprono la zona critica)\n",
    "        - \"OK\" = connettore visibile e simile ai campioni OK di training\n",
    "        - \"KO\" = connettore visibile ma anomalo rispetto ai campioni OK\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Carica modelli (caricati una volta e riutilizzati)\n",
    "    try:\n",
    "        occ_model = load_occlusion_model(device)\n",
    "        ae_model, threshold = load_ae_and_threshold(device)\n",
    "    except (FileNotFoundError, NameError) as e:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Modelli non trovati o classi non definite. \"\n",
    "            f\"Assicurati di aver eseguito step1 e step2. Errore: {e}\"\n",
    "        )\n",
    "    \n",
    "    # STEP 1: Verifica occlusione\n",
    "    x_occ = preprocess_image(image_path, device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = occ_model(x_occ)\n",
    "        pred_vis = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Se pred_vis == 0 → OCCLUSION\n",
    "    if pred_vis == 0:\n",
    "        return \"OCCLUSION\"\n",
    "    \n",
    "    # STEP 2: Anomaly detection (solo se visibile)\n",
    "    x_ae = preprocess_image_for_ae(image_path, device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        reconstructed = ae_model(x_ae)\n",
    "        # Calcola errore MSE medio su [C, H, W]\n",
    "        mse = nn.MSELoss(reduction='mean')\n",
    "        error = mse(reconstructed, x_ae).item()\n",
    "    \n",
    "    # Se errore > threshold → KO (anomalo)\n",
    "    if error > threshold:\n",
    "        return \"KO\"\n",
    "    else:\n",
    "        return \"OK\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I modelli vengono caricati automaticamente da classify_connector()\n",
    "# Ma se vuoi caricarli manualmente per testare:\n",
    "\n",
    "# Nota: Le classi OcclusionCNN e ConvAE devono essere in memoria\n",
    "# (eseguite da step1 e step2) oppure importate dai file Python\n",
    "\n",
    "# Esempio di caricamento manuale:\n",
    "# occ_model = load_occlusion_model(device)\n",
    "# ae_model, threshold = load_ae_and_threshold(device)\n",
    "# print(\"Modelli caricati con successo!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test su immagini locali\n",
    "# Modifica questi path secondo la tua struttura\n",
    "\n",
    "test_images = [\n",
    "    \"Data/connectors/conn1/20251106110559_TOP.png\",\n",
    "    \"Data/connectors/conn2/20251106110559_TOP.png\",\n",
    "    \"Data/connectors/conn3/20251106110559_TOP.png\",\n",
    "]\n",
    "\n",
    "print(\"Test classificazione locale:\\n\")\n",
    "for img_path in test_images:\n",
    "    img_path_obj = Path(img_path)\n",
    "    if not img_path_obj.is_absolute():\n",
    "        img_path_obj = PROJECT_ROOT / img_path_obj\n",
    "    \n",
    "    if img_path_obj.exists():\n",
    "        try:\n",
    "            result = classify_connector(str(img_path_obj), device=device)\n",
    "            print(f\"  {img_path_obj.name} ({img_path_obj.parent.name}): {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {img_path_obj.name}: ❌ ERRORE - {e}\")\n",
    "    else:\n",
    "        print(f\"  {img_path}: ⚠️  Immagine non trovata\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}